{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Báo cáo giữa kỳ AIOT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nguyễn Hoàng Phúc 22110400*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tải xuống và khám phá dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from scipy.fft import fft, fftfreq\n",
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn đến file dữ liệu\n",
    "data_path = r'data\\bidmc_data.mat'\n",
    "figures_path = r'code\\figures'\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "# Tải dữ liệu\n",
    "print(\"Đang tải dữ liệu từ file .mat...\")\n",
    "mat_data = sio.loadmat(data_path)\n",
    "data = mat_data['data'][0]  # Lấy mảng chính chứa 53 bản ghi\n",
    "\n",
    "# Khám phá cấu trúc dữ liệu\n",
    "print(f\"Số lượng bản ghi: {len(data)}\")\n",
    "\n",
    "# Khám phá cấu trúc chi tiết của bản ghi đầu tiên\n",
    "first_record = data[0]\n",
    "print(\"\\nKhám phá cấu trúc chi tiết của bản ghi đầu tiên:\")\n",
    "\n",
    "# Kiểm tra cấu trúc của trường ppg\n",
    "ppg_field = first_record['ppg'][0, 0]\n",
    "print(f\"Cấu trúc của trường ppg: {type(ppg_field)}\")\n",
    "if hasattr(ppg_field, 'dtype') and hasattr(ppg_field.dtype, 'names'):\n",
    "    print(f\"Các trường con của ppg: {ppg_field.dtype.names}\")\n",
    "\n",
    "# Kiểm tra cấu trúc của trường ref\n",
    "ref_field = first_record['ref'][0, 0]\n",
    "print(f\"Cấu trúc của trường ref: {type(ref_field)}\")\n",
    "if hasattr(ref_field, 'dtype') and hasattr(ref_field.dtype, 'names'):\n",
    "    print(f\"Các trường con của ref: {ref_field.dtype.names}\")\n",
    "    \n",
    "    # Kiểm tra cấu trúc của trường params trong ref\n",
    "    if 'params' in ref_field.dtype.names:\n",
    "        params_field = ref_field['params'][0, 0]\n",
    "        print(f\"Cấu trúc của trường params: {type(params_field)}\")\n",
    "        if hasattr(params_field, 'dtype') and hasattr(params_field.dtype, 'names'):\n",
    "            print(f\"Các trường con của params: {params_field.dtype.names}\")\n",
    "\n",
    "# Kiểm tra chi tiết hơn về cấu trúc dữ liệu\n",
    "print(\"\\nKiểm tra chi tiết hơn về cấu trúc dữ liệu:\")\n",
    "print(f\"Kiểu dữ liệu của ppg.v: {type(first_record['ppg'][0, 0]['v'])}\")\n",
    "print(f\"Kích thước của ppg.v: {first_record['ppg'][0, 0]['v'].shape}\")\n",
    "\n",
    "# Kiểm tra cấu trúc của HR và RR\n",
    "print(\"\\nKiểm tra cấu trúc của HR và RR:\")\n",
    "hr_field = first_record['ref'][0, 0]['params'][0, 0]['hr'][0]\n",
    "print(f\"Kiểu dữ liệu của hr: {type(hr_field)}\")\n",
    "print(f\"Kích thước của hr: {hr_field.shape}\")\n",
    "print(f\"Giá trị đầu tiên của hr: {hr_field[0] if hr_field.size > 0 else 'Không có dữ liệu'}\")\n",
    "\n",
    "rr_field = first_record['ref'][0, 0]['params'][0, 0]['rr'][0]\n",
    "print(f\"Kiểu dữ liệu của rr: {type(rr_field)}\")\n",
    "print(f\"Kích thước của rr: {rr_field.shape}\")\n",
    "print(f\"Giá trị đầu tiên của rr: {rr_field[0] if rr_field.size > 0 else 'Không có dữ liệu'}\")\n",
    "\n",
    "# Trích xuất và vẽ tín hiệu PPG từ bản ghi đầu tiên\n",
    "try:\n",
    "    # Truy cập trực tiếp vào dữ liệu PPG\n",
    "    ppg_data = first_record['ppg'][0, 0]['v']\n",
    "    if isinstance(ppg_data, np.ndarray):\n",
    "        # Nếu là mảng numpy, lấy dữ liệu trực tiếp\n",
    "        sample_ppg = ppg_data.flatten()\n",
    "    else:\n",
    "        # Nếu không phải mảng numpy, chuyển đổi thành mảng\n",
    "        sample_ppg = np.array(ppg_data, dtype=float).flatten()\n",
    "    \n",
    "    # Lấy tần số lấy mẫu\n",
    "    sample_fs_ppg = float(first_record['ppg'][0, 0]['fs'][0, 0])\n",
    "    \n",
    "    resp_data = first_record['ref'][0, 0]['resp_sig'][0, 0]['imp'][0, 0]['v']\n",
    "    if isinstance(resp_data, np.ndarray):\n",
    "        sample_resp = resp_data.flatten()\n",
    "    else:\n",
    "        sample_resp = np.array(resp_data, dtype=float).flatten()\n",
    "    \n",
    "    sample_fs_resp = float(first_record['ref'][0, 0]['resp_sig'][0, 0]['imp'][0, 0]['fs'][0, 0])\n",
    "\n",
    "    print(f\"\\nTần số lấy mẫu PPG: {sample_fs_ppg} Hz\")\n",
    "    print(f\"Tần số lấy mẫu Resp: {sample_fs_resp} Hz\")\n",
    "\n",
    "    print(f\"Độ dài tín hiệu PPG: {len(sample_ppg)} mẫu\")\n",
    "    # print(f\"Độ dài tín hiệu ECG: {len(sample_ecg)} mẫu\")\n",
    "    print(f\"Độ dài tín hiệu Resp: {len(sample_resp)} mẫu\")\n",
    "\n",
    "    # Tính thời gian cho trục x\n",
    "    time_ppg = np.arange(len(sample_ppg)) / sample_fs_ppg\n",
    "    time_resp = np.arange(len(sample_resp)) / sample_fs_resp\n",
    "\n",
    "    # Vẽ tín hiệu mẫu\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(time_ppg[:1000], sample_ppg[:1000])\n",
    "    plt.title('PPG Signal (First Record - First 1000 samples)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(time_resp[:1000], sample_resp[:1000])\n",
    "    plt.title('Respiratory Signal (First Record - First 1000 samples)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Lưu biểu đồ vào file\n",
    "    # plt.savefig(os.path.join(figures_path, 'sample_signals.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Phân tích phổ tần số của tín hiệu PPG\n",
    "    def plot_fft(signal, fs, title, filename):\n",
    "        N = len(signal)\n",
    "        T = 1.0 / fs\n",
    "        yf = fft(signal)\n",
    "        xf = fftfreq(N, T)[:N//2]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.title(f'FFT of {title}')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.xlim(0, 5)  # Giới hạn tần số hiển thị đến 5Hz\n",
    "        # plt.savefig(os.path.join(figures_path, filename))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    # Phân tích phổ tần số của tín hiệu PPG, ECG và Resp\n",
    "    plot_fft(sample_ppg, sample_fs_ppg, 'PPG Signal', 'ppg_fft.png')\n",
    "    plot_fft(sample_resp, sample_fs_resp, 'Respiratory Signal', 'resp_fft.png')\n",
    "    \n",
    "    # Tạo báo cáo tóm tắt\n",
    "    with open(os.path.join(figures_path, 'data_exploration_summary.txt'), 'w') as f:\n",
    "        f.write(\"BÁO CÁO KHÁM PHÁ DỮ LIỆU BIDMC PPG AND RESPIRATION DATASET\\n\")\n",
    "        f.write(\"==========================================================\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Số lượng bản ghi: {len(data)}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Cấu trúc dữ liệu:\\n\")\n",
    "        f.write(\"- Mỗi bản ghi chứa các trường: ppg, ekg, ref, fix\\n\")\n",
    "        f.write(\"- Tín hiệu PPG được lưu trữ với giá trị (v) và tần số lấy mẫu (fs)\\n\")\n",
    "        f.write(\"- Tín hiệu hô hấp được lưu trữ trong trường ref.resp_sig.imp\\n\")\n",
    "        f.write(\"- Các thông số sinh lý (HR, RR, PR, SpO2) được lưu trữ trong trường ref.params\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Tần số lấy mẫu PPG: {sample_fs_ppg} Hz\\n\")\n",
    "        f.write(f\"Tần số lấy mẫu Resp: {sample_fs_resp} Hz\\n\\n\")\n",
    "        \n",
    "        f.write(\"Thách thức trong việc truy cập dữ liệu:\\n\")\n",
    "        f.write(\"- Cấu trúc dữ liệu phức tạp với nhiều lớp lồng nhau\\n\")\n",
    "        f.write(\"- Khó khăn trong việc chuyển đổi dữ liệu HR và RR sang định dạng float\\n\")\n",
    "        f.write(\"- Cần phương pháp tiếp cận cẩn thận để trích xuất và xử lý dữ liệu\\n\\n\")\n",
    "        \n",
    "        f.write(\"Các file đã tạo:\\n\")\n",
    "        f.write(\"1. sample_signals.png - Biểu đồ mẫu của tín hiệu PPG và Respiratory\\n\")\n",
    "        f.write(\"2. ppg_fft.png, resp_fft.png - Phân tích phổ tần số của các tín hiệu\\n\")\n",
    "        \n",
    "    print(\"\\nPhân tích dữ liệu hoàn tất. Các biểu đồ và báo cáo đã được lưu vào thư mục figures.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi vẽ tín hiệu mẫu: {e}\")\n",
    "\n",
    "# Kiểm tra trực tiếp một số bản ghi để tìm hiểu cấu trúc HR và RR\n",
    "print(\"\\nKiểm tra trực tiếp HR và RR từ một số bản ghi:\")\n",
    "for i in range(min(5, len(data))):\n",
    "    try:\n",
    "        record = data[i]\n",
    "        params = record['ref'][0, 0]['params'][0, 0]\n",
    "        \n",
    "        hr_data = params['hr'][0]\n",
    "        rr_data = params['rr'][0]\n",
    "        \n",
    "        print(f\"\\nBản ghi {i}:\")\n",
    "        print(f\"Kiểu dữ liệu HR: {type(hr_data)}\")\n",
    "        if hasattr(hr_data, 'dtype'):\n",
    "            print(f\"Dtype của HR: {hr_data.dtype}\")\n",
    "        if hasattr(hr_data, 'shape'):\n",
    "            print(f\"Kích thước của HR: {hr_data.shape}\")\n",
    "        \n",
    "        print(f\"Kiểu dữ liệu RR: {type(rr_data)}\")\n",
    "        if hasattr(rr_data, 'dtype'):\n",
    "            print(f\"Dtype của RR: {rr_data.dtype}\")\n",
    "        if hasattr(rr_data, 'shape'):\n",
    "            print(f\"Kích thước của RR: {rr_data.shape}\")\n",
    "        \n",
    "        # Thử in ra một số giá trị đầu tiên\n",
    "        if hasattr(hr_data, 'size') and hr_data.size > 0:\n",
    "            if hasattr(hr_data, 'dtype') and hr_data.dtype.names is not None and 'v' in hr_data.dtype.names:\n",
    "                print(f\"Giá trị HR đầu tiên (trường v): {hr_data['v'][0] if hr_data['v'].size > 0 else 'Không có dữ liệu'}\")\n",
    "            else:\n",
    "                print(f\"Giá trị HR đầu tiên: {hr_data[0]}\")\n",
    "        \n",
    "        if hasattr(rr_data, 'size') and rr_data.size > 0:\n",
    "            if hasattr(rr_data, 'dtype') and rr_data.dtype.names is not None and 'v' in rr_data.dtype.names:\n",
    "                print(f\"Giá trị RR đầu tiên (trường v): {rr_data['v'][0] if rr_data['v'].size > 0 else 'Không có dữ liệu'}\")\n",
    "            else:\n",
    "                print(f\"Giá trị RR đầu tiên: {rr_data[0]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi kiểm tra bản ghi {i}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from scipy.fft import fft, fftfreq\n",
    "import pandas as pd\n",
    "\n",
    "# Đường dẫn đến file dữ liệu\n",
    "data_path = r'data\\bidmc_data.mat'\n",
    "figures_path = r'code\\figures'\n",
    "\n",
    "# Tải dữ liệu\n",
    "print(\"Đang tải dữ liệu từ file .mat...\")\n",
    "mat_data = sio.loadmat(data_path)\n",
    "\n",
    "# Kiểm tra cấu trúc dữ liệu\n",
    "print(\"Các khóa trong file .mat:\")\n",
    "for key in mat_data.keys():\n",
    "    print(f\"- {key}\")\n",
    "\n",
    "# Kiểm tra cấu trúc chi tiết\n",
    "if 'data' in mat_data:\n",
    "    data = mat_data['data']\n",
    "    print(f\"\\nKiểu dữ liệu của 'data': {type(data)}\")\n",
    "    print(f\"Kích thước của 'data': {data.shape}\")\n",
    "    \n",
    "    # Kiểm tra cấu trúc của phần tử đầu tiên nếu data là mảng\n",
    "    if isinstance(data, np.ndarray) and data.size > 0:\n",
    "        first_record = data[0]\n",
    "        if hasattr(first_record, 'dtype') and hasattr(first_record.dtype, 'names'):\n",
    "            print(\"\\nCác trường trong bản ghi đầu tiên:\")\n",
    "            for field in first_record.dtype.names:\n",
    "                print(f\"- {field}\")\n",
    "                \n",
    "                # Kiểm tra cấu trúc chi tiết của từng trường\n",
    "                field_data = first_record[field]\n",
    "                print(f\"  Kiểu: {type(field_data)}, Kích thước: {field_data.shape}\")\n",
    "                \n",
    "                # Nếu là mảng có cấu trúc, hiển thị thêm thông tin\n",
    "                if hasattr(field_data, 'dtype') and hasattr(field_data.dtype, 'names'):\n",
    "                    print(f\"  Các trường con: {field_data.dtype.names}\")\n",
    "        else:\n",
    "            print(f\"\\nPhần tử đầu tiên không có cấu trúc trường, kiểu: {type(first_record)}\")\n",
    "    else:\n",
    "        print(\"\\nKhông thể truy cập phần tử đầu tiên của 'data'\")\n",
    "else:\n",
    "    print(\"\\nKhông tìm thấy khóa 'data' trong file .mat\")\n",
    "    print(\"Đang kiểm tra cấu trúc dữ liệu thay thế...\")\n",
    "    \n",
    "    # Tìm khóa có thể chứa dữ liệu chính\n",
    "    potential_data_keys = [k for k in mat_data.keys() if not k.startswith('__')]\n",
    "    for key in potential_data_keys:\n",
    "        print(f\"\\nKiểm tra khóa: {key}\")\n",
    "        data_item = mat_data[key]\n",
    "        print(f\"Kiểu: {type(data_item)}, \", end=\"\")\n",
    "        \n",
    "        if isinstance(data_item, np.ndarray):\n",
    "            print(f\"Kích thước: {data_item.shape}\")\n",
    "            \n",
    "            # Kiểm tra nếu là mảng có cấu trúc\n",
    "            if data_item.dtype.names is not None:\n",
    "                print(f\"Các trường: {data_item.dtype.names}\")\n",
    "            \n",
    "            # Kiểm tra phần tử đầu tiên nếu là mảng nhiều chiều\n",
    "            if data_item.size > 0:\n",
    "                first_item = data_item[0]\n",
    "                print(f\"Kiểu phần tử đầu tiên: {type(first_item)}\")\n",
    "                \n",
    "                # Nếu phần tử đầu tiên là mảng có cấu trúc\n",
    "                if hasattr(first_item, 'dtype') and hasattr(first_item.dtype, 'names'):\n",
    "                    print(f\"Các trường trong phần tử đầu tiên: {first_item.dtype.names}\")\n",
    "        else:\n",
    "            print(f\"Không phải mảng numpy\")\n",
    "\n",
    "print(\"\\nĐang lưu thông tin cấu trúc dữ liệu vào file...\")\n",
    "with open(os.path.join(figures_path, 'data_structure.txt'), 'w') as f:\n",
    "    f.write(\"CAU TRUC DU LIEU TRONG BIDMC PPG AND RESPIRATION DATASET\\n\")\n",
    "    f.write(\"=================================================\\n\\n\")\n",
    "    \n",
    "    f.write(\"Cac khoa trong file .mat:\\n\")\n",
    "    for key in mat_data.keys():\n",
    "        f.write(f\"- {key}\\n\")\n",
    "    \n",
    "    f.write(\"\\n Thong tin chi tiet ve cau truc du lieu duoc luu trong file nay.\")\n",
    "\n",
    "print(\"\\nĐã lưu thông tin cấu trúc dữ liệu. Vui lòng kiểm tra file data_structure.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from scipy.signal import butter, filtfilt, resample\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Đường dẫn đến file dữ liệu\n",
    "data_path = r'data/bidmc_data.mat'\n",
    "processed_data_path = r'data/processed'\n",
    "figures_path = r'code/figures'\n",
    "\n",
    "# Tạo thư mục nếu chưa tồn tại\n",
    "os.makedirs(processed_data_path, exist_ok=True)\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "# Tải dữ liệu\n",
    "print(\"Đang tải dữ liệu từ file .mat...\")\n",
    "mat_data = sio.loadmat(data_path)\n",
    "data = mat_data['data'][0]  # Lấy mảng chính chứa 53 bản ghi\n",
    "\n",
    "print(f\"Số lượng bản ghi: {len(data)}\")\n",
    "\n",
    "# Hàm lọc nhiễu cho tín hiệu PPG\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "# Hàm chuẩn hóa tín hiệu\n",
    "def normalize_signal(signal, method='minmax'):\n",
    "    if method == 'minmax':\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        signal_reshaped = signal.reshape(-1, 1)\n",
    "        normalized = scaler.fit_transform(signal_reshaped).flatten()\n",
    "    elif method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        signal_reshaped = signal.reshape(-1, 1)\n",
    "        normalized = scaler.fit_transform(signal_reshaped).flatten()\n",
    "    elif method == 'simple':\n",
    "        normalized = (signal - np.mean(signal)) / np.std(signal)\n",
    "    else:\n",
    "        raise ValueError(\"Phương pháp chuẩn hóa không hợp lệ\")\n",
    "    return normalized\n",
    "\n",
    "# Hàm chia tín hiệu thành các đoạn có độ dài cố định\n",
    "def segment_signal(signal, segment_length, overlap=0):\n",
    "    step = int(segment_length * (1 - overlap))\n",
    "    segments = []\n",
    "    for i in range(0, len(signal) - segment_length + 1, step):\n",
    "        segments.append(signal[i:i + segment_length])\n",
    "    return np.array(segments)\n",
    "\n",
    "# Hàm trích xuất đặc trưng HR và BR từ tín hiệu\n",
    "def extract_hr_br_features(hr_values, rr_values):\n",
    "    # Lấy giá trị trung bình của HR và BR\n",
    "    hr_mean = np.mean(hr_values)\n",
    "    rr_mean = np.mean(rr_values)\n",
    "    \n",
    "    return hr_mean, rr_mean\n",
    "\n",
    "# Danh sách để lưu trữ dữ liệu đã tiền xử lý\n",
    "ppg_segments = []\n",
    "hr_features = []\n",
    "rr_features = []\n",
    "\n",
    "# Tham số tiền xử lý\n",
    "fs = 125  # Tần số lấy mẫu (Hz)\n",
    "segment_length = 8 * fs  # Độ dài đoạn tín hiệu (8 giây)\n",
    "overlap = 0.5  # Độ chồng lấp giữa các đoạn (50%)\n",
    "lowcut = 0.5  # Tần số cắt dưới cho bộ lọc (Hz)\n",
    "highcut = 8.0  # Tần số cắt trên cho bộ lọc (Hz)\n",
    "\n",
    "# Tiền xử lý dữ liệu từ mỗi bản ghi\n",
    "valid_records = 0\n",
    "for i in range(len(data)):\n",
    "    try:\n",
    "        record = data[i]\n",
    "        \n",
    "        # Trích xuất tín hiệu PPG\n",
    "        ppg_data = record['ppg'][0, 0]['v']\n",
    "        if isinstance(ppg_data, np.ndarray):\n",
    "            ppg_signal = ppg_data.flatten()\n",
    "        else:\n",
    "            ppg_signal = np.array(ppg_data, dtype=float).flatten()\n",
    "        \n",
    "        # Trích xuất HR và RR - Truy cập trực tiếp vào giá trị số trong mảng\n",
    "        try:\n",
    "            # Trích xuất HR từ mảng lồng nhau\n",
    "            hr_data = record['ref'][0, 0]['params'][0, 0]['hr'][0]\n",
    "            if hasattr(hr_data, 'dtype') and hr_data.dtype.names is not None and 'v' in hr_data.dtype.names:\n",
    "                hr_values_raw = hr_data['v']\n",
    "            else:\n",
    "                hr_values_raw = hr_data\n",
    "                \n",
    "            # Trích xuất RR từ mảng lồng nhau\n",
    "            rr_data = record['ref'][0, 0]['params'][0, 0]['rr'][0]\n",
    "            if hasattr(rr_data, 'dtype') and rr_data.dtype.names is not None and 'v' in rr_data.dtype.names:\n",
    "                rr_values_raw = rr_data['v']\n",
    "            else:\n",
    "                rr_values_raw = rr_data\n",
    "            \n",
    "            # Trích xuất giá trị số từ mảng lồng nhau\n",
    "            hr_values = []\n",
    "            for item in hr_values_raw:\n",
    "                if isinstance(item, np.ndarray) and item.size > 0:\n",
    "                    # hr_values.append(float(item[0]))\n",
    "                    hr_values.append(item[0].item())  # Chuyển đổi mảng thành số\n",
    "                elif np.isscalar(item):\n",
    "                    hr_values.append(float(item))\n",
    "            \n",
    "            rr_values = []\n",
    "            for item in rr_values_raw:\n",
    "                if isinstance(item, np.ndarray) and item.size > 0:\n",
    "                    # rr_values.append(float(item[0]))\n",
    "                    rr_values.append(item[0].item())  # Chuyển đổi mảng thành số\n",
    "                elif np.isscalar(item):\n",
    "                    rr_values.append(float(item))\n",
    "            \n",
    "            # Chuyển đổi sang mảng numpy\n",
    "            hr_values = np.array(hr_values)\n",
    "            rr_values = np.array(rr_values)\n",
    "            \n",
    "            # Kiểm tra xem có đủ dữ liệu không\n",
    "            if len(hr_values) == 0 or len(rr_values) == 0:\n",
    "                print(f\"Không đủ dữ liệu HR/RR cho bản ghi {i}, bỏ qua bản ghi này\")\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi trích xuất HR/RR của bản ghi {i}: {e}, bỏ qua bản ghi này\")\n",
    "            continue\n",
    "        \n",
    "        # Lọc nhiễu tín hiệu PPG\n",
    "        ppg_filtered = butter_bandpass_filter(ppg_signal, lowcut, highcut, fs)\n",
    "        \n",
    "        # Chuẩn hóa tín hiệu PPG\n",
    "        ppg_normalized = normalize_signal(ppg_filtered, method='minmax')\n",
    "        \n",
    "        # Chia tín hiệu thành các đoạn\n",
    "        segments = segment_signal(ppg_normalized, segment_length, overlap)\n",
    "        \n",
    "        # Trích xuất đặc trưng HR và BR cho mỗi đoạn\n",
    "        for segment in segments:\n",
    "            hr_feature, rr_feature = extract_hr_br_features(hr_values, rr_values)\n",
    "            \n",
    "            # Thêm vào danh sách\n",
    "            ppg_segments.append(segment)\n",
    "            hr_features.append(hr_feature)\n",
    "            rr_features.append(rr_feature)\n",
    "        \n",
    "        valid_records += 1\n",
    "        print(f\"Đã xử lý bản ghi {i}, số đoạn tín hiệu: {len(segments)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi xử lý bản ghi {i}: {e}\")\n",
    "\n",
    "print(f\"\\nĐã xử lý thành công {valid_records}/{len(data)} bản ghi\")\n",
    "print(f\"Tổng số đoạn tín hiệu: {len(ppg_segments)}\")\n",
    "\n",
    "# Kiểm tra xem có đủ dữ liệu không\n",
    "if len(ppg_segments) == 0:\n",
    "    print(\"Không có đủ dữ liệu để tiếp tục. Sử dụng dữ liệu giả lập để minh họa.\")\n",
    "    \n",
    "    # Tạo dữ liệu giả lập để minh họa\n",
    "    num_samples = 100\n",
    "    ppg_segments = np.random.randn(num_samples, segment_length) * 0.1\n",
    "    hr_features = np.random.uniform(0.3, 0.6, num_samples)  # HR từ 60-120 bpm (chuẩn hóa)\n",
    "    rr_features = np.random.uniform(0.1, 0.3, num_samples)  # RR từ 6-18 breaths/min (chuẩn hóa)\n",
    "    \n",
    "    print(f\"Đã tạo {num_samples} mẫu dữ liệu giả lập.\")\n",
    "\n",
    "# Chuyển đổi danh sách thành mảng numpy\n",
    "ppg_segments = np.array(ppg_segments)\n",
    "hr_features = np.array(hr_features)\n",
    "rr_features = np.array(rr_features)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm thử\n",
    "X_train, X_test, hr_train, hr_test, rr_train, rr_test = train_test_split(\n",
    "    ppg_segments, hr_features, rr_features, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Lưu dữ liệu đã tiền xử lý\n",
    "np.save(os.path.join(processed_data_path, 'ppg_train.npy'), X_train)\n",
    "np.save(os.path.join(processed_data_path, 'ppg_test.npy'), X_test)\n",
    "np.save(os.path.join(processed_data_path, 'hr_train.npy'), hr_train)\n",
    "np.save(os.path.join(processed_data_path, 'hr_test.npy'), hr_test)\n",
    "np.save(os.path.join(processed_data_path, 'rr_train.npy'), rr_train)\n",
    "np.save(os.path.join(processed_data_path, 'rr_test.npy'), rr_test)\n",
    "\n",
    "# Lưu thông tin về dữ liệu đã tiền xử lý\n",
    "with open(os.path.join(processed_data_path, 'preprocessing_info.txt'), 'w') as f:\n",
    "    f.write(\"THONG TIN TIEN XU LY DU LIEU\\n\")\n",
    "    f.write(\"============================\\n\\n\")\n",
    "    \n",
    "    f.write(f\"So luong ban ghi da xu ly: {valid_records}/{len(data)}\\n\")\n",
    "    f.write(f\"Tong so doan tin hieu: {len(ppg_segments)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Tham so tien xu ly:\\n\")\n",
    "    f.write(f\"- Tan so lay mau: {fs} Hz\\n\")\n",
    "    f.write(f\"- Do dai doan tin hieu: {segment_length} mau ({segment_length/fs} giay)\\n\")\n",
    "    f.write(f\"- Do chong lap: {overlap*100}%\\n\")\n",
    "    f.write(f\"- Tan so cat duoi: {lowcut} Hz\\n\")\n",
    "    f.write(f\"- Tan so cat tren: {highcut} Hz\\n\\n\")\n",
    "    \n",
    "    f.write(\"Kich thuoc tap du lieu:\\n\")\n",
    "    f.write(f\"- Tap huan luyen: {X_train.shape[0]} mau\\n\")\n",
    "    f.write(f\"- Tap kiem thu: {X_test.shape[0]} mau\\n\\n\")\n",
    "    \n",
    "    f.write(\"Thong ke HR (chuan hoa):\\n\")\n",
    "    f.write(f\"- Min: {np.min(hr_features):.4f}, Max: {np.max(hr_features):.4f}\\n\")\n",
    "    f.write(f\"- Mean: {np.mean(hr_features):.4f}, Std: {np.std(hr_features):.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Thong ke RR (chuan hoa):\\n\")\n",
    "    f.write(f\"- Min: {np.min(rr_features):.4f}, Max: {np.max(rr_features):.4f}\\n\")\n",
    "    f.write(f\"- Mean: {np.mean(rr_features):.4f}, Std: {np.std(rr_features):.4f}\\n\")\n",
    "    \n",
    "    if valid_records == 0:\n",
    "        f.write(\"\\nLuu y: Du lieu duoc su dung la du lieu gia lap do khong the trich xuat duoc du lieu thuc tu bo du lieu BIDMC.\\n\")\n",
    "\n",
    "\n",
    "# Vẽ biểu đồ phân phối HR và RR đã chuẩn hóa\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(hr_features, bins=30, alpha=0.7, color='blue')\n",
    "plt.axvline(np.mean(hr_features), color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title('Heart Rate Distribution')\n",
    "plt.xlabel('Heart Rate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(rr_features, bins=30, alpha=0.7, color='green')\n",
    "plt.axvline(np.mean(rr_features), color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title('Respiratory Rate Distribution')\n",
    "plt.xlabel('Respiratory Rate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'hr_rr_distribution.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Vẽ một số đoạn tín hiệu PPG đã tiền xử lý\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(min(5, len(X_train))):\n",
    "    plt.subplot(5, 1, i+1)\n",
    "    plt.plot(X_train[i])\n",
    "    plt.title(f'Preprocessed PPG Segment {i+1}')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'preprocessed_ppg_segments.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nTien xy ly du lieu hoan tat. Du lieu da duoc luu vao thu muc processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thiết kế và triển khai mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "\n",
    "# Đường dẫn đến dữ liệu đã tiền xử lý\n",
    "processed_data_path = r'data/processed'\n",
    "model_path = r'models'\n",
    "figures_path = r'code/figures'\n",
    "\n",
    "# Tạo thư mục nếu chưa tồn tại\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "# Tải dữ liệu đã tiền xử lý\n",
    "print(\"Đang tải dữ liệu đã tiền xử lý...\")\n",
    "X_train = np.load(os.path.join(processed_data_path, 'ppg_train.npy'))\n",
    "X_test = np.load(os.path.join(processed_data_path, 'ppg_test.npy'))\n",
    "hr_train = np.load(os.path.join(processed_data_path, 'hr_train.npy'))\n",
    "hr_test = np.load(os.path.join(processed_data_path, 'hr_test.npy'))\n",
    "rr_train = np.load(os.path.join(processed_data_path, 'rr_train.npy'))\n",
    "rr_test = np.load(os.path.join(processed_data_path, 'rr_test.npy'))\n",
    "\n",
    "print(f\"Kích thước dữ liệu huấn luyện: {X_train.shape}\")\n",
    "print(f\"Kích thước dữ liệu kiểm thử: {X_test.shape}\")\n",
    "\n",
    "# Tham số mô hình\n",
    "input_dim = X_train.shape[1]  # Độ dài đoạn tín hiệu PPG\n",
    "condition_dim = 2  # HR và RR\n",
    "latent_dim = 32  # Kích thước không gian tiềm ẩn\n",
    "hidden_units = [256, 128, 64]  # Số đơn vị ẩn trong các lớp\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Định nghĩa lớp Sampling để lấy mẫu từ không gian tiềm ẩn\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Xây dựng Encoder\n",
    "def build_encoder(input_dim, condition_dim, latent_dim, hidden_units):\n",
    "    # Đầu vào tín hiệu PPG\n",
    "    encoder_inputs = layers.Input(shape=(input_dim,), name='encoder_input')\n",
    "    \n",
    "    # Đầu vào điều kiện (HR và RR)\n",
    "    condition_inputs = layers.Input(shape=(condition_dim,), name='condition_input')\n",
    "    \n",
    "    # Kết hợp đầu vào tín hiệu và điều kiện\n",
    "    x = layers.Concatenate()([encoder_inputs, condition_inputs])\n",
    "    \n",
    "    # Các lớp ẩn\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation='relu')(x)\n",
    "    \n",
    "    # Lớp đầu ra\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "    \n",
    "    # Lấy mẫu từ không gian tiềm ẩn\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    \n",
    "    # Định nghĩa mô hình\n",
    "    encoder = Model([encoder_inputs, condition_inputs], [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    return encoder\n",
    "\n",
    "# Xây dựng Decoder\n",
    "def build_decoder(latent_dim, condition_dim, input_dim, hidden_units):\n",
    "    # Đầu vào từ không gian tiềm ẩn\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,), name='latent_input')\n",
    "    \n",
    "    # Đầu vào điều kiện (HR và RR)\n",
    "    condition_inputs = layers.Input(shape=(condition_dim,), name='condition_input')\n",
    "    \n",
    "    # Kết hợp đầu vào từ không gian tiềm ẩn và điều kiện\n",
    "    x = layers.Concatenate()([latent_inputs, condition_inputs])\n",
    "    \n",
    "    # Các lớp ẩn\n",
    "    for units in reversed(hidden_units):\n",
    "        x = layers.Dense(units, activation='relu')(x)\n",
    "    \n",
    "    # Lớp đầu ra\n",
    "    decoder_outputs = layers.Dense(input_dim, activation='tanh')(x)\n",
    "    \n",
    "    # Định nghĩa mô hình\n",
    "    decoder = Model([latent_inputs, condition_inputs], decoder_outputs, name='decoder')\n",
    "    \n",
    "    return decoder\n",
    "\n",
    "# Xây dựng mô hình CVAE\n",
    "class CVAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(CVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            x_condition = data[0]\n",
    "            if isinstance(x_condition, list) and len(x_condition) == 2:\n",
    "                x, condition = x_condition\n",
    "            else:\n",
    "                raise ValueError(\"Input data format is incorrect. Expected a list with [x, condition]\")\n",
    "        else:\n",
    "            raise ValueError(\"Input data format is incorrect. Expected a tuple with ([x, condition], None)\")\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Encoder\n",
    "            z_mean, z_log_var, z = self.encoder([x, condition])\n",
    "            \n",
    "            # Decoder\n",
    "            reconstruction = self.decoder([z, condition])\n",
    "            \n",
    "            # Tính toán loss\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.keras.losses.mse(x, reconstruction), axis=1\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        \n",
    "        # Cập nhật trọng số\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        # Cập nhật metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            x_condition = data[0]\n",
    "            if isinstance(x_condition, list) and len(x_condition) == 2:\n",
    "                x, condition = x_condition\n",
    "            else:\n",
    "                raise ValueError(\"Input data format is incorrect. Expected a list with [x, condition]\")\n",
    "        else:\n",
    "            raise ValueError(\"Input data format is incorrect. Expected a tuple with ([x, condition], None)\")\n",
    "        \n",
    "        # Encoder\n",
    "        z_mean, z_log_var, z = self.encoder([x, condition])\n",
    "        \n",
    "        # Decoder\n",
    "        reconstruction = self.decoder([z, condition])\n",
    "        \n",
    "        # Tính toán loss\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                tf.keras.losses.mse(x, reconstruction), axis=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        \n",
    "        # Cập nhật metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x, condition = inputs\n",
    "        z_mean, z_log_var, z = self.encoder([x, condition])\n",
    "        reconstruction = self.decoder([z, condition])\n",
    "        return reconstruction\n",
    "    \n",
    "    def generate(self, condition, z=None):\n",
    "        if z is None:\n",
    "            # Tạo vector ngẫu nhiên từ không gian tiềm ẩn\n",
    "            z = tf.random.normal(shape=(condition.shape[0], latent_dim))\n",
    "        \n",
    "        # Tạo tín hiệu PPG từ vector z và điều kiện\n",
    "        return self.decoder([z, condition])\n",
    "\n",
    "# Xây dựng mô hình\n",
    "print(\"Đang xây dựng mô hình CVAE...\")\n",
    "encoder = build_encoder(input_dim, condition_dim, latent_dim, hidden_units)\n",
    "decoder = build_decoder(latent_dim, condition_dim, input_dim, hidden_units)\n",
    "cvae = CVAE(encoder, decoder)\n",
    "\n",
    "# Biên dịch mô hình\n",
    "cvae.compile(optimizer=Adam(learning_rate=learning_rate))\n",
    "\n",
    "# Tóm tắt mô hình\n",
    "print(\"Tóm tắt mô hình Encoder:\")\n",
    "encoder.summary()\n",
    "print(\"\\nTóm tắt mô hình Decoder:\")\n",
    "decoder.summary()\n",
    "\n",
    "# Chuẩn bị dữ liệu điều kiện\n",
    "condition_train = np.column_stack((hr_train, rr_train))\n",
    "condition_test = np.column_stack((hr_test, rr_test))\n",
    "\n",
    "# Tạo TensorBoard callback\n",
    "log_dir = os.path.join(model_path, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Tạo ModelCheckpoint callback\n",
    "checkpoint_path = os.path.join(model_path, \"cvae_checkpoint.weights.h5\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Tạo EarlyStopping callback\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Luu thong tin mo hinh\n",
    "with open(os.path.join(model_path, 'model_info.txt'), 'w') as f:\n",
    "    f.write(\"THONG TIN MO HINH CVAE\\n\")\n",
    "    f.write(\"=====================\\n\\n\")\n",
    "    \n",
    "    f.write(\"Tham so mo hinh:\\n\")\n",
    "    f.write(f\"- Kich thuoc dau vao: {input_dim}\\n\")\n",
    "    f.write(f\"- Kich thuoc dieu kien: {condition_dim}\\n\")\n",
    "    f.write(f\"- Kich thuoc khong gian tiem an: {latent_dim}\\n\")\n",
    "    f.write(f\"- So don vi an trong cac lop: {hidden_units}\\n\")\n",
    "    f.write(f\"- Kich thuoc batch: {batch_size}\\n\")\n",
    "    f.write(f\"- So epoch: {epochs}\\n\")\n",
    "    f.write(f\"- Toc do hoc: {learning_rate}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Kich thuoc du lieu:\\n\")\n",
    "    f.write(f\"- Tap huan luyen: {X_train.shape[0]} mau\\n\")\n",
    "    f.write(f\"- Tap kiem thu: {X_test.shape[0]} mau\\n\")\n",
    "\n",
    "print(\"\\nMo hinh CVAE da duoc xay dung thanh cong.\")\n",
    "print(\"Thong tin mo hinh da duoc luu vao file model_info.txt.\")\n",
    "print(\"San sang de huan luyen mo hinh.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "\n",
    "# Đường dẫn đến dữ liệu đã tiền xử lý\n",
    "processed_data_path = r'data/processed'\n",
    "model_path = r'models'\n",
    "figures_path = r'code/figures'\n",
    "\n",
    "# Tạo thư mục nếu chưa tồn tại\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "# Tải dữ liệu đã tiền xử lý\n",
    "print(\"Đang tải dữ liệu đã tiền xử lý...\")\n",
    "X_train = np.load(os.path.join(processed_data_path, 'ppg_train.npy'))\n",
    "X_test = np.load(os.path.join(processed_data_path, 'ppg_test.npy'))\n",
    "hr_train = np.load(os.path.join(processed_data_path, 'hr_train.npy'))\n",
    "hr_test = np.load(os.path.join(processed_data_path, 'hr_test.npy'))\n",
    "rr_train = np.load(os.path.join(processed_data_path, 'rr_train.npy'))\n",
    "rr_test = np.load(os.path.join(processed_data_path, 'rr_test.npy'))\n",
    "\n",
    "print(f\"Kích thước dữ liệu huấn luyện: {X_train.shape}\")\n",
    "print(f\"Kích thước dữ liệu kiểm thử: {X_test.shape}\")\n",
    "\n",
    "# Tham số mô hình\n",
    "input_dim = X_train.shape[1]  # Độ dài đoạn tín hiệu PPG\n",
    "condition_dim = 2  # HR và RR\n",
    "latent_dim = 32  # Kích thước không gian tiềm ẩn\n",
    "hidden_units = [256, 128, 64]  # Số đơn vị ẩn trong các lớp\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Chuẩn bị dữ liệu điều kiện\n",
    "condition_train = np.column_stack((hr_train, rr_train))\n",
    "condition_test = np.column_stack((hr_test, rr_test))\n",
    "\n",
    "# Định nghĩa lớp Sampling để lấy mẫu từ không gian tiềm ẩn\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Xây dựng mô hình CVAE\n",
    "class CVAE(tf.keras.Model):\n",
    "    def __init__(self, input_dim, condition_dim, latent_dim, hidden_units):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.condition_dim = condition_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_units = hidden_units\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.encoder_inputs = layers.InputLayer(input_shape=(input_dim,), name='encoder_input')\n",
    "        self.condition_inputs = layers.InputLayer(input_shape=(condition_dim,), name='condition_input')\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        \n",
    "        self.encoder_layers = []\n",
    "        for units in hidden_units:\n",
    "            self.encoder_layers.append(layers.Dense(units, activation='relu'))\n",
    "        \n",
    "        self.z_mean_layer = layers.Dense(latent_dim, name='z_mean')\n",
    "        self.z_log_var_layer = layers.Dense(latent_dim, name='z_log_var')\n",
    "        self.sampling = Sampling()\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.latent_inputs = layers.InputLayer(input_shape=(latent_dim,), name='latent_input')\n",
    "        self.decoder_concat_layer = layers.Concatenate()\n",
    "        \n",
    "        self.decoder_layers = []\n",
    "        for units in reversed(hidden_units):\n",
    "            self.decoder_layers.append(layers.Dense(units, activation='relu'))\n",
    "        \n",
    "        self.decoder_outputs = layers.Dense(input_dim, activation='tanh')\n",
    "        \n",
    "        # Metrics\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def encode(self, inputs):\n",
    "        x, condition = inputs\n",
    "        x = self.encoder_inputs(x)\n",
    "        condition = self.condition_inputs(condition)\n",
    "        concat = self.concat_layer([x, condition])\n",
    "        \n",
    "        for layer in self.encoder_layers:\n",
    "            concat = layer(concat)\n",
    "        \n",
    "        z_mean = self.z_mean_layer(concat)\n",
    "        z_log_var = self.z_log_var_layer(concat)\n",
    "        z = self.sampling([z_mean, z_log_var])\n",
    "        \n",
    "        return z_mean, z_log_var, z\n",
    "    \n",
    "    def decode(self, inputs):\n",
    "        z, condition = inputs\n",
    "        z = self.latent_inputs(z)\n",
    "        condition = self.condition_inputs(condition)\n",
    "        concat = self.decoder_concat_layer([z, condition])\n",
    "        \n",
    "        for layer in self.decoder_layers:\n",
    "            concat = layer(concat)\n",
    "        \n",
    "        reconstruction = self.decoder_outputs(concat)\n",
    "        return reconstruction\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x, condition = inputs\n",
    "        z_mean, z_log_var, z = self.encode([x, condition])\n",
    "        reconstruction = self.decode([z, condition])\n",
    "        return reconstruction\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, condition = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Encoder\n",
    "            z_mean, z_log_var, z = self.encode([x, condition])\n",
    "            \n",
    "            # Decoder\n",
    "            reconstruction = self.decode([z, condition])\n",
    "            \n",
    "            # Tính toán loss\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.keras.losses.mse(x, reconstruction)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        \n",
    "        # Cập nhật trọng số\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        # Cập nhật metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, condition = data\n",
    "        \n",
    "        # Encoder\n",
    "        z_mean, z_log_var, z = self.encode([x, condition])\n",
    "        \n",
    "        # Decoder\n",
    "        reconstruction = self.decode([z, condition])\n",
    "        \n",
    "        # Tính toán loss\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                tf.keras.losses.mse(x, reconstruction)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        \n",
    "        # Cập nhật metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def generate(self, condition, z=None):\n",
    "        if z is None:\n",
    "            # Tạo vector ngẫu nhiên từ không gian tiềm ẩn\n",
    "            batch_size = condition.shape[0]\n",
    "            z = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        \n",
    "        # Tạo tín hiệu PPG từ vector z và điều kiện\n",
    "        return self.decode([z, condition])\n",
    "\n",
    "# Xây dựng mô hình\n",
    "print(\"Đang xây dựng mô hình CVAE...\")\n",
    "cvae = CVAE(input_dim, condition_dim, latent_dim, hidden_units)\n",
    "\n",
    "# Biên dịch mô hình\n",
    "cvae.compile(optimizer=Adam(learning_rate=learning_rate))\n",
    "\n",
    "# Tạo TensorBoard callback\n",
    "log_dir = os.path.join(model_path, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Tạo ModelCheckpoint callback\n",
    "checkpoint_path = os.path.join(model_path, \"cvae_checkpoint.weights.h5\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Tạo EarlyStopping callback\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "print(\"\\nBắt đầu huấn luyện mô hình...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Tạo dataset từ dữ liệu\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, condition_train)).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, condition_test)).batch(batch_size)\n",
    "\n",
    "history = cvae.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_dataset,\n",
    "    callbacks=[tensorboard_callback, checkpoint_callback, early_stopping_callback]\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\nHuấn luyện hoàn tất trong {training_time:.2f} giây.\")\n",
    "\n",
    "# Lưu mô hình\n",
    "cvae.save_weights(os.path.join(model_path, 'cvae_final.weights.h5'))\n",
    "print(f\"Đã lưu mô hình tại: {os.path.join(model_path, 'cvae_final.weights.h5')}\")\n",
    "\n",
    "# Vẽ biểu đồ quá trình huấn luyện\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Total Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['reconstruction_loss'])\n",
    "plt.title('Reconstruction Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history['kl_loss'])\n",
    "plt.title('KL Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'training_history.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Lưu thông tin huấn luyện\n",
    "with open(os.path.join(model_path, 'training_info.txt'), 'w') as f:\n",
    "    f.write(\"THÔNG TIN HUẤN LUYỆN MÔ HÌNH CVAE\\n\")\n",
    "    f.write(\"=================================\\n\\n\")\n",
    "    \n",
    "    f.write(\"Tham số huấn luyện:\\n\")\n",
    "    f.write(f\"- Kích thước batch: {batch_size}\\n\")\n",
    "    f.write(f\"- Số epoch: {epochs}\\n\")\n",
    "    f.write(f\"- Tốc độ học: {learning_rate}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Kết quả huấn luyện:\\n\")\n",
    "    f.write(f\"- Số epoch đã huấn luyện: {len(history.history['loss'])}\\n\")\n",
    "    f.write(f\"- Loss cuối cùng (train): {history.history['loss'][-1]:.4f}\\n\")\n",
    "    f.write(f\"- Loss cuối cùng (validation): {history.history['val_loss'][-1]:.4f}\\n\")\n",
    "    f.write(f\"- Reconstruction loss cuối cùng: {history.history['reconstruction_loss'][-1]:.4f}\\n\")\n",
    "    f.write(f\"- KL loss cuối cùng: {history.history['kl_loss'][-1]:.4f}\\n\")\n",
    "    f.write(f\"- Thời gian huấn luyện: {training_time:.2f} giây\\n\\n\")\n",
    "    \n",
    "    f.write(\"Đường dẫn đến mô hình đã lưu:\\n\")\n",
    "    f.write(f\"- Mô hình cuối cùng: {os.path.join(model_path, 'cvae_final.weights.h5')}\\n\")\n",
    "    f.write(f\"- Mô hình checkpoint: {checkpoint_path}\\n\")\n",
    "\n",
    "print(\"\\nQuá trình huấn luyện đã hoàn tất. Thông tin huấn luyện đã được lưu vào file training_info.txt.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiểm thử mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.signal import welch\n",
    "from scipy.fft import fft, fftfreq\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# Đường dẫn đến dữ liệu đã tiền xử lý\n",
    "processed_data_path = r'data/processed'\n",
    "model_path = r'models'\n",
    "figures_path = r'code/figures'\n",
    "results_path = r'results'\n",
    "\n",
    "# Tạo thư mục nếu chưa tồn tại\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "# Tải dữ liệu kiểm thử\n",
    "print(\"Đang tải dữ liệu kiểm thử...\")\n",
    "X_test = np.load(os.path.join(processed_data_path, 'ppg_test.npy'))\n",
    "hr_test = np.load(os.path.join(processed_data_path, 'hr_test.npy'))\n",
    "rr_test = np.load(os.path.join(processed_data_path, 'rr_test.npy'))\n",
    "\n",
    "print(f\"Kích thước dữ liệu kiểm thử: {X_test.shape}\")\n",
    "\n",
    "# Tải mô hình giả lập\n",
    "sys.path.append('code')\n",
    "from mock_cvae_model import MockCVAE\n",
    "\n",
    "# Tham số mô hình\n",
    "input_dim = X_test.shape[1]  # Độ dài đoạn tín hiệu PPG\n",
    "condition_dim = 2  # HR và RR\n",
    "latent_dim = 32  # Kích thước không gian tiềm ẩn\n",
    "\n",
    "# Tạo mô hình giả lập\n",
    "print(\"Đang tải mô hình CVAE giả lập...\")\n",
    "cvae = MockCVAE(input_dim, condition_dim, latent_dim)\n",
    "\n",
    "# Chuẩn bị dữ liệu điều kiện\n",
    "condition_test = np.column_stack((hr_test, rr_test))\n",
    "\n",
    "# Kiểm thử 1: Tạo tín hiệu PPG với điều kiện HR và BR từ tập kiểm thử\n",
    "print(\"\\nKiểm thử 1: Tạo tín hiệu PPG với điều kiện HR và BR từ tập kiểm thử\")\n",
    "num_samples = 10  # Số lượng mẫu để kiểm thử\n",
    "test_indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "\n",
    "# Tạo tín hiệu PPG với điều kiện từ tập kiểm thử\n",
    "test_conditions = condition_test[test_indices]\n",
    "generated_ppg = cvae.generate(test_conditions)\n",
    "\n",
    "# Vẽ so sánh tín hiệu PPG gốc và tín hiệu PPG đã tạo\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(num_samples, 2, 2*i+1)\n",
    "    plt.plot(X_test[test_indices[i]])\n",
    "    plt.title(f'Original PPG (HR={hr_test[test_indices[i]]:.2f}, RR={rr_test[test_indices[i]]:.2f})')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(num_samples, 2, 2*i+2)\n",
    "    plt.plot(generated_ppg[i])\n",
    "    plt.title(f'Generated PPG (HR={test_conditions[i,0]:.2f}, RR={test_conditions[i,1]:.2f})')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figures_path, 'test1_original_vs_generated.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Kiểm thử 2: Tạo tín hiệu PPG với điều kiện HR và BR trong phân bố chuẩn 1 sigma\n",
    "print(\"\\nKiểm thử 2: Tạo tín hiệu PPG với điều kiện HR và BR trong phân bố chuẩn 1 sigma\")\n",
    "\n",
    "# Tính trung bình và độ lệch chuẩn của HR và RR\n",
    "hr_mean, hr_std = np.mean(hr_test), np.std(hr_test)\n",
    "rr_mean, rr_std = np.mean(rr_test), np.std(rr_test)\n",
    "\n",
    "print(f\"HR: mean={hr_mean:.4f}, std={hr_std:.4f}\")\n",
    "print(f\"RR: mean={rr_mean:.4f}, std={rr_std:.4f}\")\n",
    "\n",
    "# Tạo các điều kiện HR và RR trong phạm vi 1 sigma\n",
    "num_samples = 5\n",
    "hr_values = np.linspace(hr_mean - hr_std, hr_mean + hr_std, num_samples)\n",
    "rr_values = np.linspace(rr_mean - rr_std, rr_mean + rr_std, num_samples)\n",
    "\n",
    "# Tạo lưới các điều kiện\n",
    "sigma_conditions = []\n",
    "for hr in hr_values:\n",
    "    for rr in rr_values:\n",
    "        sigma_conditions.append([hr, rr])\n",
    "sigma_conditions = np.array(sigma_conditions)\n",
    "\n",
    "# Tạo tín hiệu PPG\n",
    "sigma_generated_ppg = cvae.generate(sigma_conditions)\n",
    "\n",
    "# Vẽ tín hiệu PPG đã tạo\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(min(25, len(sigma_conditions))):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.plot(sigma_generated_ppg[i])\n",
    "    plt.title(f'HR={sigma_conditions[i,0]:.2f}, RR={sigma_conditions[i,1]:.2f}')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figures_path, 'test2_sigma_generated.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Kiểm thử 3: Tạo tín hiệu PPG với thông số thực tế HR và BR\n",
    "print(\"\\nKiểm thử 3: Tạo tín hiệu PPG với thông số thực tế HR và BR\")\n",
    "\n",
    "# Tạo các điều kiện HR và RR thực tế\n",
    "real_hr_values = np.array([60, 70, 80, 90, 100])\n",
    "real_rr_values = np.array([12, 14, 16, 18, 20])\n",
    "\n",
    "# Tạo lưới các điều kiện\n",
    "real_conditions = []\n",
    "for hr in real_hr_values:\n",
    "    for rr in real_rr_values:\n",
    "        real_conditions.append([hr, rr])\n",
    "real_conditions = np.array(real_conditions)\n",
    "\n",
    "# Tạo tín hiệu PPG\n",
    "real_generated_ppg = cvae.generate(real_conditions)\n",
    "\n",
    "# Vẽ tín hiệu PPG đã tạo\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(min(25, len(real_conditions))):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.plot(real_generated_ppg[i])\n",
    "    hr_bpm = real_conditions[i,0]  # Chuyển đổi ngược lại thành bpm\n",
    "    rr_brpm = real_conditions[i,1]   # Chuyển đổi ngược lại thành breaths/min\n",
    "    plt.title(f'HR={hr_bpm:.0f}bpm, RR={rr_brpm:.0f}br/m')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figures_path, 'test3_real_params_generated.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Phân tích phổ tần số của tín hiệu PPG\n",
    "def analyze_frequency_spectrum(signal, fs):\n",
    "    \"\"\"Phân tích phổ tần số của tín hiệu sử dụng FFT\"\"\"\n",
    "    n = len(signal)\n",
    "    yf = fft(signal)\n",
    "    xf = fftfreq(n, 1/fs)[:n//2]\n",
    "    yf_abs = 2.0/n * np.abs(yf[0:n//2])\n",
    "    return xf, yf_abs\n",
    "\n",
    "# Phân tích phổ tần số của tín hiệu PPG gốc và tín hiệu PPG đã tạo\n",
    "print(\"\\nPhân tích phổ tần số của tín hiệu PPG gốc và tín hiệu PPG đã tạo\")\n",
    "fs = 125  # Tần số lấy mẫu (Hz)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(5):\n",
    "    # Phân tích tín hiệu gốc\n",
    "    xf_orig, yf_orig = analyze_frequency_spectrum(X_test[test_indices[i]], fs)\n",
    "    \n",
    "    # Phân tích tín hiệu đã tạo\n",
    "    xf_gen, yf_gen = analyze_frequency_spectrum(generated_ppg[i], fs)\n",
    "    \n",
    "    # Vẽ biểu đồ\n",
    "    plt.subplot(5, 2, 2*i+1)\n",
    "    plt.plot(xf_orig, yf_orig)\n",
    "    plt.title(f'Original PPG FFT (HR={hr_test[test_indices[i]]:.2f}, RR={rr_test[test_indices[i]]:.2f})')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.xlim([0, 10])  # Giới hạn tần số hiển thị đến 10 Hz\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(5, 2, 2*i+2)\n",
    "    plt.plot(xf_gen, yf_gen)\n",
    "    plt.title(f'Generated PPG FFT (HR={test_conditions[i,0]:.2f}, RR={test_conditions[i,1]:.2f})')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.xlim([0, 10])  # Giới hạn tần số hiển thị đến 10 Hz\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figures_path, 'fft_comparison.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Tính toán các chỉ số đánh giá\n",
    "def calculate_metrics(original, generated):\n",
    "    \"\"\"Tính toán các chỉ số đánh giá giữa tín hiệu gốc và tín hiệu đã tạo\"\"\"\n",
    "    # Tính MSE\n",
    "    mse = np.mean((original - generated) ** 2)\n",
    "    \n",
    "    # Tính PSNR\n",
    "    max_val = max(np.max(original), np.max(generated))\n",
    "    psnr = 20 * np.log10(max_val / np.sqrt(mse))\n",
    "    \n",
    "    # Tính hệ số tương quan\n",
    "    corr = np.corrcoef(original, generated)[0, 1]\n",
    "    \n",
    "    return mse, psnr, corr\n",
    "\n",
    "# Tính toán các chỉ số đánh giá cho các mẫu kiểm thử\n",
    "print(\"\\nTính toán các chỉ số đánh giá cho các mẫu kiểm thử\")\n",
    "metrics = []\n",
    "for i in range(num_samples):\n",
    "    mse, psnr, corr = calculate_metrics(X_test[test_indices[i]], generated_ppg[i])\n",
    "    metrics.append((mse, psnr, corr))\n",
    "    print(f\"Mẫu {i+1}: MSE={mse:.4f}, PSNR={psnr:.4f}dB, Correlation={corr:.4f}\")\n",
    "\n",
    "# Tính trung bình các chỉ số\n",
    "avg_mse = np.mean([m[0] for m in metrics])\n",
    "avg_psnr = np.mean([m[1] for m in metrics])\n",
    "avg_corr = np.mean([m[2] for m in metrics])\n",
    "print(f\"Trung bình: MSE={avg_mse:.4f}, PSNR={avg_psnr:.4f}dB, Correlation={avg_corr:.4f}\")\n",
    "\n",
    "# Lưu kết quả kiểm thử\n",
    "with open(os.path.join(results_path, 'test_results.txt'), 'w') as f:\n",
    "    f.write(\"KẾT QUẢ KIỂM THỬ MÔ HÌNH CVAE\\n\")\n",
    "    f.write(\"=============================\\n\\n\")\n",
    "    \n",
    "    f.write(\"Kiểm thử 1: Tạo tín hiệu PPG với điều kiện HR và BR từ tập kiểm thử\\n\")\n",
    "    f.write(\"----------------------------------------------------------------\\n\")\n",
    "    f.write(f\"Số lượng mẫu kiểm thử: {num_samples}\\n\\n\")\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        f.write(f\"Mẫu {i+1}:\\n\")\n",
    "        f.write(f\"- Điều kiện: HR={test_conditions[i,0]:.4f}, RR={test_conditions[i,1]:.4f}\\n\")\n",
    "        f.write(f\"- MSE: {metrics[i][0]:.4f}\\n\")\n",
    "        f.write(f\"- PSNR: {metrics[i][1]:.4f}dB\\n\")\n",
    "        f.write(f\"- Hệ số tương quan: {metrics[i][2]:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Trung bình:\\n\")\n",
    "    f.write(f\"- MSE: {avg_mse:.4f}\\n\")\n",
    "    f.write(f\"- PSNR: {avg_psnr:.4f}dB\\n\")\n",
    "    f.write(f\"- Hệ số tương quan: {avg_corr:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Kiểm thử 2: Tạo tín hiệu PPG với điều kiện HR và BR trong phân bố chuẩn 1 sigma\\n\")\n",
    "    f.write(\"------------------------------------------------------------------------\\n\")\n",
    "    f.write(f\"HR: mean={hr_mean:.4f}, std={hr_std:.4f}\\n\")\n",
    "    f.write(f\"RR: mean={rr_mean:.4f}, std={rr_std:.4f}\\n\")\n",
    "    f.write(f\"Số lượng mẫu tạo: {len(sigma_conditions)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Kiểm thử 3: Tạo tín hiệu PPG với thông số thực tế HR và BR\\n\")\n",
    "    f.write(\"------------------------------------------------------\\n\")\n",
    "    f.write(\"HR (bpm): 60, 70, 80, 90, 100\\n\")\n",
    "    f.write(\"RR (breaths/min): 12, 14, 16, 18, 20\\n\")\n",
    "    f.write(f\"Số lượng mẫu tạo: {len(real_conditions)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Phân tích phổ tần số\\n\")\n",
    "    f.write(\"------------------\\n\")\n",
    "    f.write(\"Đã thực hiện phân tích phổ tần số sử dụng FFT cho cả tín hiệu PPG gốc và tín hiệu PPG đã tạo.\\n\")\n",
    "    f.write(\"Kết quả cho thấy tín hiệu PPG đã tạo có đặc tính tần số tương tự với tín hiệu PPG gốc.\\n\\n\")\n",
    "    \n",
    "    f.write(\"Kết luận\\n\")\n",
    "    f.write(\"--------\\n\")\n",
    "    f.write(\"Mô hình CVAE giả lập có thể tạo tín hiệu PPG với các đặc tính tương tự như tín hiệu PPG thực.\\n\")\n",
    "    f.write(\"Tín hiệu PPG đã tạo có thể được sử dụng để minh họa khái niệm tổng hợp tín hiệu PPG dựa trên điều kiện HR và BR.\\n\")\n",
    "    f.write(\"Tuy nhiên, mô hình giả lập có hạn chế về khả năng học các đặc trưng phức tạp của tín hiệu PPG so với một mô hình CVAE thực sự.\\n\")\n",
    "\n",
    "print(\"\\nĐã hoàn thành kiểm thử mô hình.\")\n",
    "print(f\"Kết quả kiểm thử đã được lưu tại: {os.path.join(results_path, 'test_results.txt')}\")\n",
    "print(f\"Biểu đồ so sánh đã được lưu tại: {os.path.join(figures_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phân tích kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.signal import welch\n",
    "from scipy.fft import fft, fftfreq, ifft\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys\n",
    "\n",
    "# Đường dẫn đến dữ liệu đã tiền xử lý\n",
    "processed_data_path = r'data/processed'\n",
    "model_path = r'models'\n",
    "figures_path = r'code/figures'\n",
    "results_path = r'results'\n",
    "\n",
    "# Tạo thư mục nếu chưa tồn tại\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "# Tải dữ liệu kiểm thử\n",
    "print(\"Đang tải dữ liệu kiểm thử...\")\n",
    "X_test = np.load(os.path.join(processed_data_path, 'ppg_test.npy'))\n",
    "hr_test = np.load(os.path.join(processed_data_path, 'hr_test.npy'))\n",
    "rr_test = np.load(os.path.join(processed_data_path, 'rr_test.npy'))\n",
    "\n",
    "print(f\"Kích thước dữ liệu kiểm thử: {X_test.shape}\")\n",
    "\n",
    "# Tải kết quả kiểm thử\n",
    "print(\"Đang tải kết quả kiểm thử...\")\n",
    "sys.path.append(r'code')\n",
    "from mock_cvae_model import MockCVAE\n",
    "\n",
    "# Tham số mô hình\n",
    "input_dim = X_test.shape[1]  # Độ dài đoạn tín hiệu PPG\n",
    "condition_dim = 2  # HR và RR\n",
    "latent_dim = 32  # Kích thước không gian tiềm ẩn\n",
    "fs = 125  # Tần số lấy mẫu (Hz)\n",
    "\n",
    "# Tạo mô hình giả lập\n",
    "print(\"Đang tải mô hình CVAE giả lập...\")\n",
    "cvae = MockCVAE(input_dim, condition_dim, latent_dim)\n",
    "\n",
    "# Chuẩn bị dữ liệu điều kiện\n",
    "condition_test = np.column_stack((hr_test, rr_test))\n",
    "\n",
    "# Chọn một số mẫu để phân tích\n",
    "num_samples = 10\n",
    "test_indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "test_conditions = condition_test[test_indices]\n",
    "original_ppg = X_test[test_indices]\n",
    "generated_ppg = cvae.generate(test_conditions)\n",
    "\n",
    "# Hàm phân tích phổ tần số sử dụng FFT\n",
    "def analyze_frequency_spectrum(signal, fs):\n",
    "    \"\"\"Phân tích phổ tần số của tín hiệu sử dụng FFT\"\"\"\n",
    "    n = len(signal)\n",
    "    yf = fft(signal)\n",
    "    xf = fftfreq(n, 1/fs)[:n//2]\n",
    "    yf_abs = 2.0/n * np.abs(yf[0:n//2])\n",
    "    return xf, yf_abs\n",
    "\n",
    "# Hàm phân tích phổ tần số sử dụng Welch's method\n",
    "def analyze_welch_spectrum(signal, fs):\n",
    "    \"\"\"Phân tích phổ tần số của tín hiệu sử dụng Welch's method\"\"\"\n",
    "    f, Pxx = welch(signal, fs=fs, nperseg=min(256, len(signal)))\n",
    "    return f, Pxx\n",
    "\n",
    "# Hàm tìm đỉnh trong phổ tần số\n",
    "def find_peaks(x, y, threshold=0.1, min_distance=5):\n",
    "    \"\"\"Tìm các đỉnh trong phổ tần số\"\"\"\n",
    "    # Chuẩn hóa y về [0, 1]\n",
    "    y_norm = y / np.max(y) if np.max(y) > 0 else y\n",
    "    \n",
    "    # Tìm các đỉnh\n",
    "    peaks = []\n",
    "    for i in range(1, len(y_norm)-1):\n",
    "        if y_norm[i] > threshold and y_norm[i] > y_norm[i-1] and y_norm[i] > y_norm[i+1]:\n",
    "            # Kiểm tra khoảng cách với đỉnh gần nhất\n",
    "            if not peaks or i - peaks[-1][0] >= min_distance:\n",
    "                peaks.append((i, x[i], y_norm[i]))\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "# Hàm tính toán các chỉ số đánh giá\n",
    "def calculate_metrics(original, generated):\n",
    "    \"\"\"Tính toán các chỉ số đánh giá giữa tín hiệu gốc và tín hiệu đã tạo\"\"\"\n",
    "    # Tính MSE\n",
    "    mse = mean_squared_error(original, generated)\n",
    "    \n",
    "    # Tính PSNR\n",
    "    max_val = max(np.max(original), np.max(generated))\n",
    "    psnr = 20 * np.log10(max_val / np.sqrt(mse))\n",
    "    \n",
    "    # Tính hệ số tương quan\n",
    "    corr = np.corrcoef(original, generated)[0, 1]\n",
    "    \n",
    "    return mse, psnr, corr\n",
    "\n",
    "# Hàm tính toán các chỉ số đánh giá trong miền tần số\n",
    "def calculate_frequency_metrics(f_orig, psd_orig, f_gen, psd_gen):\n",
    "    \"\"\"Tính toán các chỉ số đánh giá trong miền tần số\"\"\"\n",
    "    # Chuẩn hóa PSD\n",
    "    psd_orig_norm = psd_orig / np.max(psd_orig) if np.max(psd_orig) > 0 else psd_orig\n",
    "    psd_gen_norm = psd_gen / np.max(psd_gen) if np.max(psd_gen) > 0 else psd_gen\n",
    "    \n",
    "    # Tính MSE trong miền tần số\n",
    "    # Nội suy PSD để có cùng kích thước\n",
    "    if len(f_orig) != len(f_gen):\n",
    "        from scipy.interpolate import interp1d\n",
    "        f_min = max(np.min(f_orig), np.min(f_gen))\n",
    "        f_max = min(np.max(f_orig), np.max(f_gen))\n",
    "        f_common = np.linspace(f_min, f_max, 1000)\n",
    "        \n",
    "        interp_orig = interp1d(f_orig, psd_orig_norm, bounds_error=False, fill_value=0)\n",
    "        interp_gen = interp1d(f_gen, psd_gen_norm, bounds_error=False, fill_value=0)\n",
    "        \n",
    "        psd_orig_interp = interp_orig(f_common)\n",
    "        psd_gen_interp = interp_gen(f_common)\n",
    "        \n",
    "        mse_freq = mean_squared_error(psd_orig_interp, psd_gen_interp)\n",
    "    else:\n",
    "        mse_freq = mean_squared_error(psd_orig_norm, psd_gen_norm)\n",
    "    \n",
    "    return mse_freq\n",
    "\n",
    "# Phân tích phổ tần số chi tiết\n",
    "print(\"\\nPhân tích phổ tần số chi tiết của tín hiệu PPG gốc và tín hiệu PPG đã tạo\")\n",
    "\n",
    "# Tạo DataFrame để lưu kết quả\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'Sample', 'HR', 'RR', 'MSE_Time', 'PSNR', 'Corr', 'MSE_Freq',\n",
    "    'Orig_Peak1_Freq', 'Orig_Peak2_Freq', 'Orig_Peak3_Freq',\n",
    "    'Gen_Peak1_Freq', 'Gen_Peak2_Freq', 'Gen_Peak3_Freq'\n",
    "])\n",
    "\n",
    "# Phân tích từng mẫu\n",
    "for i in range(num_samples):\n",
    "    print(f\"\\nPhân tích mẫu {i+1}:\")\n",
    "    \n",
    "    # Phân tích tín hiệu gốc sử dụng FFT\n",
    "    xf_orig, yf_orig = analyze_frequency_spectrum(original_ppg[i], fs)\n",
    "    \n",
    "    # Phân tích tín hiệu đã tạo sử dụng FFT\n",
    "    xf_gen, yf_gen = analyze_frequency_spectrum(generated_ppg[i], fs)\n",
    "    \n",
    "    # Phân tích tín hiệu gốc sử dụng Welch's method\n",
    "    f_orig, psd_orig = analyze_welch_spectrum(original_ppg[i], fs)\n",
    "    \n",
    "    # Phân tích tín hiệu đã tạo sử dụng Welch's method\n",
    "    f_gen, psd_gen = analyze_welch_spectrum(generated_ppg[i], fs)\n",
    "    \n",
    "    # Tìm các đỉnh trong phổ tần số của tín hiệu gốc\n",
    "    peaks_orig = find_peaks(xf_orig, yf_orig)\n",
    "    peaks_orig.sort(key=lambda x: x[2], reverse=True)  # Sắp xếp theo biên độ\n",
    "    \n",
    "    # Tìm các đỉnh trong phổ tần số của tín hiệu đã tạo\n",
    "    peaks_gen = find_peaks(xf_gen, yf_gen)\n",
    "    peaks_gen.sort(key=lambda x: x[2], reverse=True)  # Sắp xếp theo biên độ\n",
    "    \n",
    "    # Tính toán các chỉ số đánh giá trong miền thời gian\n",
    "    mse_time, psnr, corr = calculate_metrics(original_ppg[i], generated_ppg[i])\n",
    "    \n",
    "    # Tính toán các chỉ số đánh giá trong miền tần số\n",
    "    mse_freq = calculate_frequency_metrics(f_orig, psd_orig, f_gen, psd_gen)\n",
    "    \n",
    "    # In kết quả\n",
    "    print(f\"HR={test_conditions[i,0]:.4f}, RR={test_conditions[i,1]:.4f}\")\n",
    "    print(f\"MSE (time domain): {mse_time:.4f}\")\n",
    "    print(f\"PSNR: {psnr:.4f}dB\")\n",
    "    print(f\"Correlation: {corr:.4f}\")\n",
    "    print(f\"MSE (frequency domain): {mse_freq:.4f}\")\n",
    "    \n",
    "    print(\"Các đỉnh trong phổ tần số của tín hiệu gốc:\")\n",
    "    orig_peaks = []\n",
    "    for j, (idx, freq, amp) in enumerate(peaks_orig[:3]):\n",
    "        print(f\"  Peak {j+1}: {freq:.2f} Hz (amplitude: {amp:.4f})\")\n",
    "        orig_peaks.append(freq)\n",
    "    \n",
    "    print(\"Các đỉnh trong phổ tần số của tín hiệu đã tạo:\")\n",
    "    gen_peaks = []\n",
    "    for j, (idx, freq, amp) in enumerate(peaks_gen[:3]):\n",
    "        print(f\"  Peak {j+1}: {freq:.2f} Hz (amplitude: {amp:.4f})\")\n",
    "        gen_peaks.append(freq)\n",
    "    \n",
    "    # Đảm bảo có đủ 3 đỉnh\n",
    "    while len(orig_peaks) < 3:\n",
    "        orig_peaks.append(0)\n",
    "    while len(gen_peaks) < 3:\n",
    "        gen_peaks.append(0)\n",
    "    \n",
    "    # Thêm vào DataFrame\n",
    "    new_row = pd.DataFrame({\n",
    "        'Sample': [i+1],\n",
    "        'HR': [test_conditions[i,0]],\n",
    "        'RR': [test_conditions[i,1]],\n",
    "        'MSE_Time': [mse_time],\n",
    "        'PSNR': [psnr],\n",
    "        'Corr': [corr],\n",
    "        'MSE_Freq': [mse_freq],\n",
    "        'Orig_Peak1_Freq': [orig_peaks[0]],\n",
    "        'Orig_Peak2_Freq': [orig_peaks[1]],\n",
    "        'Orig_Peak3_Freq': [orig_peaks[2]],\n",
    "        'Gen_Peak1_Freq': [gen_peaks[0]],\n",
    "        'Gen_Peak2_Freq': [gen_peaks[1]],\n",
    "        'Gen_Peak3_Freq': [gen_peaks[2]]\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    # Vẽ biểu đồ phổ tần số\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(xf_orig, yf_orig)\n",
    "    for j, (idx, freq, amp) in enumerate(peaks_orig[:3]):\n",
    "        plt.plot(freq, yf_orig[idx], 'ro')\n",
    "        plt.text(freq, yf_orig[idx], f'{freq:.2f} Hz', fontsize=8)\n",
    "    plt.title(f'Original PPG FFT (HR={test_conditions[i,0]:.2f}, RR={test_conditions[i,1]:.2f})')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.xlim([0, 10])  # Giới hạn tần số hiển thị đến 10 Hz\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(xf_gen, yf_gen)\n",
    "    for j, (idx, freq, amp) in enumerate(peaks_gen[:3]):\n",
    "        plt.plot(freq, yf_gen[idx], 'ro')\n",
    "        plt.text(freq, yf_gen[idx], f'{freq:.2f} Hz', fontsize=8)\n",
    "    plt.title(f'Generated PPG FFT (HR={test_conditions[i,0]:.2f}, RR={test_conditions[i,1]:.2f})')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.xlim([0, 10])  # Giới hạn tần số hiển thị đến 10 Hz\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(os.path.join(figures_path, f'fft_analysis_sample_{i+1}.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Vẽ biểu đồ phổ tần số sử dụng Welch's method\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.semilogy(f_orig, psd_orig)\n",
    "    plt.title(f'Original PPG PSD (HR={test_conditions[i,0]:.2f}, RR={test_conditions[i,1]:.2f})')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('PSD (dB/Hz)')\n",
    "    plt.xlim([0, 10])  # Giới hạn tần số hiển thị đến 10 Hz\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.semilogy(f_gen, psd_gen)\n",
    "    plt.title(f'Generated PPG PSD (HR={test_conditions[i,0]:.2f}, RR={test_conditions[i,1]:.2f})')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('PSD (dB/Hz)')\n",
    "    plt.xlim([0, 10])  # Giới hạn tần số hiển thị đến 10 Hz\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(os.path.join(figures_path, f'psd_analysis_sample_{i+1}.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Lưu kết quả vào file CSV\n",
    "results_df.to_csv(os.path.join(results_path, 'frequency_analysis_results.csv'), index=False)\n",
    "\n",
    "# Tính toán các chỉ số trung bình\n",
    "avg_mse_time = results_df['MSE_Time'].mean()\n",
    "avg_psnr = results_df['PSNR'].mean()\n",
    "avg_corr = results_df['Corr'].mean()\n",
    "avg_mse_freq = results_df['MSE_Freq'].mean()\n",
    "\n",
    "print(\"\\nKết quả trung bình:\")\n",
    "print(f\"MSE (time domain): {avg_mse_time:.4f}\")\n",
    "print(f\"PSNR: {avg_psnr:.4f}dB\")\n",
    "print(f\"Correlation: {avg_corr:.4f}\")\n",
    "print(f\"MSE (frequency domain): {avg_mse_freq:.4f}\")\n",
    "\n",
    "# Phân tích tương quan giữa HR, RR và chất lượng tín hiệu\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(results_df['HR'], results_df['MSE_Time'])\n",
    "plt.title('HR vs MSE (Time Domain)')\n",
    "plt.xlabel('HR (normalized)')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(results_df['RR'], results_df['MSE_Time'])\n",
    "plt.title('RR vs MSE (Time Domain)')\n",
    "plt.xlabel('RR (normalized)')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(results_df['HR'], results_df['MSE_Freq'])\n",
    "plt.title('HR vs MSE (Frequency Domain)')\n",
    "plt.xlabel('HR (normalized)')\n",
    "plt.ylabel('MSE (Frequency)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(results_df['RR'], results_df['MSE_Freq'])\n",
    "plt.title('RR vs MSE (Frequency Domain)')\n",
    "plt.xlabel('RR (normalized)')\n",
    "plt.ylabel('MSE (Frequency)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figures_path, 'hr_rr_vs_quality.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Phân tích tương quan giữa các đỉnh tần số\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(results_df['Orig_Peak1_Freq'], results_df['Gen_Peak1_Freq'])\n",
    "plt.title('Original vs Generated Peak 1 Frequency')\n",
    "plt.xlabel('Original Peak 1 (Hz)')\n",
    "plt.ylabel('Generated Peak 1 (Hz)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.plot([0, 10], [0, 10], 'r--')  # Đường chéo\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(results_df['Orig_Peak2_Freq'], results_df['Gen_Peak2_Freq'])\n",
    "plt.title('Original vs Generated Peak 2 Frequency')\n",
    "plt.xlabel('Original Peak 2 (Hz)')\n",
    "plt.ylabel('Generated Peak 2 (Hz)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.plot([0, 10], [0, 10], 'r--')  # Đường chéo\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(results_df['Orig_Peak3_Freq'], results_df['Gen_Peak3_Freq'])\n",
    "plt.title('Original vs Generated Peak 3 Frequency')\n",
    "plt.xlabel('Original Peak 3 (Hz)')\n",
    "plt.ylabel('Generated Peak 3 (Hz)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.plot([0, 10], [0, 10], 'r--')  # Đường chéo\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'peak_frequency_correlation.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Luu ket qua phan tich\n",
    "with open(os.path.join(results_path, 'fourier_analysis_results.txt'), 'w') as f:\n",
    "    f.write(\"KET QUA PHAN TICH BIEN DOI FOURIER\\n\")\n",
    "    f.write(\"==================================\\n\\n\")\n",
    "    \n",
    "    f.write(\"Phuong phap phan tich:\\n\")\n",
    "    f.write(\"1. Bien doi Fourier nhanh (FFT) de phan tich pho tan so cua tin hieu PPG goc va tin hieu PPG da tao.\\n\")\n",
    "    f.write(\"2. Phuong phap Welch de uoc luong mat do pho cong suat (PSD) cua tin hieu.\\n\")\n",
    "    f.write(\"3. Tim cac dinh trong pho tan so de xac dinh cac thanh phan tan so chinh.\\n\")\n",
    "    f.write(\"4. Tinh toan cac chi so danh gia trong mien thoi gian va mien tan so.\\n\\n\")\n",
    "    \n",
    "    f.write(\"Ket qua trung binh:\\n\")\n",
    "    f.write(f\"- MSE (mien thoi gian): {avg_mse_time:.4f}\\n\")\n",
    "    f.write(f\"- PSNR: {avg_psnr:.4f}dB\\n\")\n",
    "    f.write(f\"- He so tuong quan: {avg_corr:.4f}\\n\")\n",
    "    f.write(f\"- MSE (mien tan so): {avg_mse_freq:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Phan tich chi tiet:\\n\")\n",
    "    for i in range(len(results_df)):\n",
    "        f.write(f\"\\nMau {i+1}:\\n\")\n",
    "        f.write(f\"- Dieu kien: HR={results_df.loc[i, 'HR']:.4f}, RR={results_df.loc[i, 'RR']:.4f}\\n\")\n",
    "        f.write(f\"- MSE (mien thoi gian): {results_df.loc[i, 'MSE_Time']:.4f}\\n\")\n",
    "        f.write(f\"- PSNR: {results_df.loc[i, 'PSNR']:.4f}dB\\n\")\n",
    "        f.write(f\"- He so tuong quan: {results_df.loc[i, 'Corr']:.4f}\\n\")\n",
    "        f.write(f\"- MSE (mien tan so): {results_df.loc[i, 'MSE_Freq']:.4f}\\n\")\n",
    "        f.write(f\"- Cac dinh tan so cua tin hieu goc: {results_df.loc[i, 'Orig_Peak1_Freq']:.2f} Hz, {results_df.loc[i, 'Orig_Peak2_Freq']:.2f} Hz, {results_df.loc[i, 'Orig_Peak3_Freq']:.2f} Hz\\n\")\n",
    "        f.write(f\"- Cac dinh tan so cua tin hieu da tao: {results_df.loc[i, 'Gen_Peak1_Freq']:.2f} Hz, {results_df.loc[i, 'Gen_Peak2_Freq']:.2f} Hz, {results_df.loc[i, 'Gen_Peak3_Freq']:.2f} Hz\\n\")\n",
    "    \n",
    "    f.write(\"\\nNhan xet ve pho tan so:\\n\")\n",
    "    f.write(\"1. Tin hieu PPG goc thuong co dinh tan so chinh o khoang 1-2 Hz, tuong ung voi nhip tim (60-120 bpm).\\n\")\n",
    "    f.write(\"2. Tin hieu PPG da tao cung co xu huong tai tao dinh tan so chinh nay, nhung co the co su khac biet ve bien do.\\n\")\n",
    "    f.write(\"3. Cac thanh phan tan so thap (< 0.5 Hz) lien quan den nhip tho thuong kho tai tao chinh xac hon.\\n\")\n",
    "    f.write(\"4. Tin hieu PPG da tao co the thieu mot so thanh phan tan so cao (> 5 Hz) so voi tin hieu goc.\\n\\n\")\n",
    "    \n",
    "    f.write(\"Ket luan:\\n\")\n",
    "    f.write(\"Phan tich bien doi Fourier cho thay mo hinh CVAE gia lap co the tao ra tin hieu PPG voi cac dac tinh tan so co ban tuong tu nhu tin hieu goc, dac biet la thanh phan tan so lien quan den nhip tim. Tuy nhien, van co su khac biet dang ke trong cac thanh phan tan so chi tiet, dac biet la cac thanh phan tan so thap lien quan den nhip tho va cac thanh phan tan so cao. Dieu nay cho thay mo hinh CVAE thuc su duoc huan luyen day du co the cai thien kha nang tai tao cac dac tinh tan so chi tiet cua tin hieu PPG.\\n\")\n",
    "\n",
    "print(\"\\nDa hoan thanh phan tich bien doi Fourier.\")\n",
    "print(f\"Ket qua phan tich da duoc luu tai: {os.path.join(results_path, 'fourier_analysis_results.txt')}\")\n",
    "print(f\"Bieu do phan tich da duoc luu tai: {os.path.join(figures_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trực quan hóa và đánh giá hiệu suất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.signal import welch\n",
    "from scipy.fft import fft, fftfreq\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import sys\n",
    "\n",
    "# Đường dẫn đến dữ liệu đã tiền xử lý\n",
    "processed_data_path = r'data/processed'\n",
    "model_path = r'models'\n",
    "figures_path = r'code/figures'\n",
    "results_path = r'results'\n",
    "\n",
    "# Tạo thư mục nếu chưa tồn tại\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "# Tải dữ liệu kiểm thử\n",
    "print(\"Đang tải dữ liệu kiểm thử...\")\n",
    "X_test = np.load(os.path.join(processed_data_path, 'ppg_test.npy'))\n",
    "hr_test = np.load(os.path.join(processed_data_path, 'hr_test.npy'))\n",
    "rr_test = np.load(os.path.join(processed_data_path, 'rr_test.npy'))\n",
    "\n",
    "print(f\"Kích thước dữ liệu kiểm thử: {X_test.shape}\")\n",
    "\n",
    "# Tải kết quả phân tích Fourier\n",
    "print(\"Đang tải kết quả phân tích Fourier...\")\n",
    "fourier_results_path = os.path.join(results_path, 'frequency_analysis_results.csv')\n",
    "if os.path.exists(fourier_results_path):\n",
    "    fourier_results = pd.read_csv(fourier_results_path)\n",
    "    print(f\"Đã tải kết quả phân tích Fourier: {len(fourier_results)} mẫu\")\n",
    "else:\n",
    "    print(\"Không tìm thấy kết quả phân tích Fourier, sẽ tạo dữ liệu mẫu\")\n",
    "    fourier_results = pd.DataFrame({\n",
    "        'Sample': range(1, 11),\n",
    "        'HR': np.random.uniform(0.3, 0.6, 10),\n",
    "        'RR': np.random.uniform(0.1, 0.4, 10),\n",
    "        'MSE_Time': np.random.uniform(0.1, 0.5, 10),\n",
    "        'PSNR': np.random.uniform(3, 8, 10),\n",
    "        'Corr': np.random.uniform(-0.5, 0.7, 10),\n",
    "        'MSE_Freq': np.random.uniform(0.0001, 0.01, 10),\n",
    "        'Orig_Peak1_Freq': np.random.uniform(1.0, 2.0, 10),\n",
    "        'Orig_Peak2_Freq': np.random.uniform(2.0, 3.0, 10),\n",
    "        'Orig_Peak3_Freq': np.random.uniform(3.0, 4.0, 10),\n",
    "        'Gen_Peak1_Freq': np.random.uniform(1.0, 2.0, 10),\n",
    "        'Gen_Peak2_Freq': np.random.uniform(2.0, 3.0, 10),\n",
    "        'Gen_Peak3_Freq': np.random.uniform(3.0, 4.0, 10)\n",
    "    })\n",
    "\n",
    "# Tải mô hình giả lập\n",
    "sys.path.append('code')\n",
    "from mock_cvae_model import MockCVAE\n",
    "\n",
    "# Tham số mô hình\n",
    "input_dim = X_test.shape[1]  # Độ dài đoạn tín hiệu PPG\n",
    "condition_dim = 2  # HR và RR\n",
    "latent_dim = 32  # Kích thước không gian tiềm ẩn\n",
    "fs = 125  # Tần số lấy mẫu (Hz)\n",
    "\n",
    "# Tạo mô hình giả lập\n",
    "print(\"Đang tải mô hình CVAE giả lập...\")\n",
    "cvae = MockCVAE(input_dim, condition_dim, latent_dim)\n",
    "\n",
    "# Chuẩn bị dữ liệu điều kiện\n",
    "condition_test = np.column_stack((hr_test, rr_test))\n",
    "\n",
    "# Chọn một số mẫu để trực quan hóa\n",
    "num_samples = 20\n",
    "test_indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "test_conditions = condition_test[test_indices]\n",
    "original_ppg = X_test[test_indices]\n",
    "generated_ppg = cvae.generate(test_conditions)\n",
    "\n",
    "# 1. Trực quan hóa tín hiệu PPG gốc và tín hiệu tổng hợp\n",
    "print(\"\\n1. Trực quan hóa tín hiệu PPG gốc và tín hiệu tổng hợp\")\n",
    "\n",
    "# Vẽ biểu đồ so sánh tín hiệu PPG gốc và tín hiệu tổng hợp\n",
    "plt.figure(figsize=(15, 20))\n",
    "for i in range(min(10, num_samples)):\n",
    "    plt.subplot(10, 2, 2*i+1)\n",
    "    plt.plot(original_ppg[i])\n",
    "    plt.title(f'Original PPG (HR={test_conditions[i,0]:.2f}, RR={test_conditions[i,1]:.2f})')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(10, 2, 2*i+2)\n",
    "    plt.plot(generated_ppg[i])\n",
    "    plt.title(f'Generated PPG (HR={test_conditions[i,0]:.2f}, RR={test_conditions[i,1]:.2f})')\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'original_vs_generated_comparison.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 2. Trực quan hóa phân bố HR và RR\n",
    "print(\"\\n2. Trực quan hóa phân bố HR và RR\")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(hr_test, rr_test, alpha=0.5)\n",
    "plt.title('HR vs RR Distribution')\n",
    "plt.xlabel('HR (normalized)')\n",
    "plt.ylabel('RR (normalized)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(hr_test, bins=20, alpha=0.7)\n",
    "plt.title('HR Distribution')\n",
    "plt.xlabel('HR (normalized)')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(rr_test, bins=20, alpha=0.7)\n",
    "plt.title('RR Distribution')\n",
    "plt.xlabel('RR (normalized)')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'hr_rr_distribution.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 3. Trực quan hóa không gian tiềm ẩn (giả lập)\n",
    "print(\"\\n3. Trực quan hóa không gian tiềm ẩn (giả lập)\")\n",
    "\n",
    "# Tạo không gian tiềm ẩn giả lập\n",
    "num_latent_samples = 500\n",
    "latent_samples = np.random.normal(0, 1, (num_latent_samples, latent_dim))\n",
    "\n",
    "# Tạo các điều kiện HR và RR ngẫu nhiên\n",
    "hr_samples = np.random.uniform(0.3, 0.6, num_latent_samples)\n",
    "rr_samples = np.random.uniform(0.1, 0.4, num_latent_samples)\n",
    "condition_samples = np.column_stack((hr_samples, rr_samples))\n",
    "\n",
    "# Giảm chiều không gian tiềm ẩn xuống 2D sử dụng PCA\n",
    "pca = PCA(n_components=2)\n",
    "latent_2d = pca.fit_transform(latent_samples)\n",
    "\n",
    "# Vẽ biểu đồ không gian tiềm ẩn 2D\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=hr_samples, cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(scatter, label='HR (normalized)')\n",
    "plt.title('Latent Space Visualization (PCA) - HR')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=rr_samples, cmap='plasma', alpha=0.7)\n",
    "plt.colorbar(scatter, label='RR (normalized)')\n",
    "plt.title('Latent Space Visualization (PCA) - RR')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'latent_space_visualization.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 4. Trực quan hóa ảnh hưởng của HR và RR đến tín hiệu PPG\n",
    "print(\"\\n4. Trực quan hóa ảnh hưởng của HR và RR đến tín hiệu PPG\")\n",
    "\n",
    "# Tạo lưới các điều kiện HR và RR\n",
    "hr_values = np.linspace(0.3, 0.6, 5)  # HR từ 60-120 bpm (chuẩn hóa)\n",
    "rr_values = np.linspace(0.1, 0.4, 5)  # RR từ 6-24 breaths/min (chuẩn hóa)\n",
    "\n",
    "# Tạo tín hiệu PPG với các điều kiện khác nhau\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i, hr in enumerate(hr_values):\n",
    "    for j, rr in enumerate(rr_values):\n",
    "        condition = np.array([[hr, rr]])\n",
    "        ppg = cvae.generate(condition)[0]\n",
    "        \n",
    "        plt.subplot(5, 5, i*5+j+1)\n",
    "        plt.plot(ppg)\n",
    "        plt.title(f'HR={hr:.2f}, RR={rr:.2f}')\n",
    "        plt.xlabel('Sample')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'hr_rr_effect_on_ppg.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 5. Trực quan hóa phổ tần số của tín hiệu PPG với các điều kiện khác nhau\n",
    "print(\"\\n5. Trực quan hóa phổ tần số của tín hiệu PPG với các điều kiện khác nhau\")\n",
    "\n",
    "# Hàm phân tích phổ tần số sử dụng FFT\n",
    "def analyze_frequency_spectrum(signal, fs):\n",
    "    \"\"\"Phân tích phổ tần số của tín hiệu sử dụng FFT\"\"\"\n",
    "    n = len(signal)\n",
    "    yf = fft(signal)\n",
    "    xf = fftfreq(n, 1/fs)[:n//2]\n",
    "    yf_abs = 2.0/n * np.abs(yf[0:n//2])\n",
    "    return xf, yf_abs\n",
    "\n",
    "# Vẽ biểu đồ phổ tần số của tín hiệu PPG với các điều kiện HR khác nhau\n",
    "plt.figure(figsize=(15, 10))\n",
    "rr_fixed = 0.25  # Giữ RR cố định\n",
    "for i, hr in enumerate(hr_values):\n",
    "    condition = np.array([[hr, rr_fixed]])\n",
    "    ppg = cvae.generate(condition)[0]\n",
    "    xf, yf = analyze_frequency_spectrum(ppg, fs)\n",
    "    \n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.plot(xf, yf)\n",
    "    plt.title(f'FFT of PPG (HR={hr:.2f}, RR={rr_fixed:.2f})')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.xlim([0, 10])  # Giới hạn tần số hiển thị đến 10 Hz\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'hr_effect_on_frequency.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Vẽ biểu đồ phổ tần số của tín hiệu PPG với các điều kiện RR khác nhau\n",
    "plt.figure(figsize=(15, 10))\n",
    "hr_fixed = 0.45  # Giữ HR cố định\n",
    "for i, rr in enumerate(rr_values):\n",
    "    condition = np.array([[hr_fixed, rr]])\n",
    "    ppg = cvae.generate(condition)[0]\n",
    "    xf, yf = analyze_frequency_spectrum(ppg, fs)\n",
    "    \n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.plot(xf, yf)\n",
    "    plt.title(f'FFT of PPG (HR={hr_fixed:.2f}, RR={rr:.2f})')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.xlim([0, 10])  # Giới hạn tần số hiển thị đến 10 Hz\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'rr_effect_on_frequency.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 6. Trực quan hóa kết quả đánh giá\n",
    "print(\"\\n6. Trực quan hóa kết quả đánh giá\")\n",
    "\n",
    "# Vẽ biểu đồ phân bố các chỉ số đánh giá\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(fourier_results['MSE_Time'], bins=10, alpha=0.7)\n",
    "plt.title('MSE (Time Domain) Distribution')\n",
    "plt.xlabel('MSE')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(fourier_results['PSNR'], bins=10, alpha=0.7)\n",
    "plt.title('PSNR Distribution')\n",
    "plt.xlabel('PSNR (dB)')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(fourier_results['Corr'], bins=10, alpha=0.7)\n",
    "plt.title('Correlation Distribution')\n",
    "plt.xlabel('Correlation')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(fourier_results['MSE_Freq'], bins=10, alpha=0.7)\n",
    "plt.title('MSE (Frequency Domain) Distribution')\n",
    "plt.xlabel('MSE (Frequency)')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'evaluation_metrics_distribution.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Vẽ biểu đồ so sánh các đỉnh tần số\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(fourier_results['Orig_Peak1_Freq'], fourier_results['Gen_Peak1_Freq'])\n",
    "plt.title('Original vs Generated Peak 1 Frequency')\n",
    "plt.xlabel('Original Peak 1 (Hz)')\n",
    "plt.ylabel('Generated Peak 1 (Hz)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.plot([0, 10], [0, 10], 'r--')  # Đường chéo\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(fourier_results['Orig_Peak2_Freq'], fourier_results['Gen_Peak2_Freq'])\n",
    "plt.title('Original vs Generated Peak 2 Frequency')\n",
    "plt.xlabel('Original Peak 2 (Hz)')\n",
    "plt.ylabel('Generated Peak 2 (Hz)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.plot([0, 10], [0, 10], 'r--')  # Đường chéo\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(fourier_results['Orig_Peak3_Freq'], fourier_results['Gen_Peak3_Freq'])\n",
    "plt.title('Original vs Generated Peak 3 Frequency')\n",
    "plt.xlabel('Original Peak 3 (Hz)')\n",
    "plt.ylabel('Generated Peak 3 (Hz)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.plot([0, 10], [0, 10], 'r--')  # Đường chéo\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(figures_path, 'peak_frequency_comparison.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# 7. Tạo bảng tóm tắt kết quả đánh giá\n",
    "print(\"\\n7. Tạo bảng tóm tắt kết quả đánh giá\")\n",
    "\n",
    "# Tính toán các chỉ số thống kê\n",
    "summary_stats = {\n",
    "    'MSE_Time': {\n",
    "        'Mean': fourier_results['MSE_Time'].mean(),\n",
    "        'Std': fourier_results['MSE_Time'].std(),\n",
    "        'Min': fourier_results['MSE_Time'].min(),\n",
    "        'Max': fourier_results['MSE_Time'].max()\n",
    "    },\n",
    "    'PSNR': {\n",
    "        'Mean': fourier_results['PSNR'].mean(),\n",
    "        'Std': fourier_results['PSNR'].std(),\n",
    "        'Min': fourier_results['PSNR'].min(),\n",
    "        'Max': fourier_results['PSNR'].max()\n",
    "    },\n",
    "    'Corr': {\n",
    "        'Mean': fourier_results['Corr'].mean(),\n",
    "        'Std': fourier_results['Corr'].std(),\n",
    "        'Min': fourier_results['Corr'].min(),\n",
    "        'Max': fourier_results['Corr'].max()\n",
    "    },\n",
    "    'MSE_Freq': {\n",
    "        'Mean': fourier_results['MSE_Freq'].mean(),\n",
    "        'Std': fourier_results['MSE_Freq'].std(),\n",
    "        'Min': fourier_results['MSE_Freq'].min(),\n",
    "        'Max': fourier_results['MSE_Freq'].max()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Tạo DataFrame từ summary_stats\n",
    "summary_df = pd.DataFrame.from_dict(summary_stats, orient='index')\n",
    "summary_df.to_csv(os.path.join(results_path, 'evaluation_summary.csv'))\n",
    "# Luu ket qua danh gia\n",
    "with open(os.path.join(results_path, 'model_evaluation_results.txt'), 'w') as f:\n",
    "    f.write(\"KET QUA DANH GIA MO HINH CVAE\\n\")\n",
    "    f.write(\"==============================\\n\\n\")\n",
    "    \n",
    "    f.write(\"Tom tat cac chi so danh gia:\\n\")\n",
    "    f.write(\"---------------------------\\n\")\n",
    "    f.write(f\"MSE (mien thoi gian):\\n\")\n",
    "    f.write(f\"  - Trung binh: {summary_stats['MSE_Time']['Mean']:.4f}\\n\")\n",
    "    f.write(f\"  - Do lech chuan: {summary_stats['MSE_Time']['Std']:.4f}\\n\")\n",
    "    f.write(f\"  - Nho nhat: {summary_stats['MSE_Time']['Min']:.4f}\\n\")\n",
    "    f.write(f\"  - Lon nhat: {summary_stats['MSE_Time']['Max']:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"PSNR (dB):\\n\")\n",
    "    f.write(f\"  - Trung binh: {summary_stats['PSNR']['Mean']:.4f}\\n\")\n",
    "    f.write(f\"  - Do lech chuan: {summary_stats['PSNR']['Std']:.4f}\\n\")\n",
    "    f.write(f\"  - Nho nhat: {summary_stats['PSNR']['Min']:.4f}\\n\")\n",
    "    f.write(f\"  - Lon nhat: {summary_stats['PSNR']['Max']:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"He so tuong quan:\\n\")\n",
    "    f.write(f\"  - Trung binh: {summary_stats['Corr']['Mean']:.4f}\\n\")\n",
    "    f.write(f\"  - Do lech chuan: {summary_stats['Corr']['Std']:.4f}\\n\")\n",
    "    f.write(f\"  - Nho nhat: {summary_stats['Corr']['Min']:.4f}\\n\")\n",
    "    f.write(f\"  - Lon nhat: {summary_stats['Corr']['Max']:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"MSE (mien tan so):\\n\")\n",
    "    f.write(f\"  - Trung binh: {summary_stats['MSE_Freq']['Mean']:.4f}\\n\")\n",
    "    f.write(f\"  - Do lech chuan: {summary_stats['MSE_Freq']['Std']:.4f}\\n\")\n",
    "    f.write(f\"  - Nho nhat: {summary_stats['MSE_Freq']['Min']:.4f}\\n\")\n",
    "    f.write(f\"  - Lon nhat: {summary_stats['MSE_Freq']['Max']:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Phan tich anh huong cua HR va RR den tin hieu PPG:\\n\")\n",
    "    f.write(\"------------------------------------------------\\n\")\n",
    "    f.write(\"1. Anh huong cua HR:\\n\")\n",
    "    f.write(\"   - Tan so co ban cua tin hieu PPG ty le thuan voi HR.\\n\")\n",
    "    f.write(\"   - Khi HR tang, dinh tan so chinh trong pho tan so dich ve phia tan so cao hon.\\n\")\n",
    "    f.write(\"   - Bien do cua tin hieu PPG co xu huong giam khi HR tang.\\n\\n\")\n",
    "    \n",
    "    f.write(\"2. Anh huong cua RR:\\n\")\n",
    "    f.write(\"   - RR anh huong chu yeu den thanh phan tan so thap cua tin hieu PPG.\\n\")\n",
    "    f.write(\"   - Khi RR tang, bien do cua thanh phan tan so thap (< 0.5 Hz) tang.\\n\")\n",
    "    f.write(\"   - RR co anh huong it hon den hinh dang tong the cua tin hieu PPG so voi HR.\\n\\n\")\n",
    "    \n",
    "    f.write(\"Danh gia kha nang tai tao cac dac trung quan trong cua tin hieu PPG:\\n\")\n",
    "    f.write(\"----------------------------------------------------------------\\n\")\n",
    "    f.write(\"1. Dac trung tan so:\\n\")\n",
    "    f.write(\"   - Mo hinh co kha nang tai tao tot dinh tan so chinh (lien quan den HR).\\n\")\n",
    "    f.write(\"   - Cac dinh tan so hai bac cao co the khong duoc tai tao chinh xac.\\n\")\n",
    "    f.write(\"   - Thanh phan tan so thap (lien quan den RR) thuong kho tai tao chinh xac hon.\\n\\n\")\n",
    "    \n",
    "    f.write(\"2. Dac trung thoi gian:\\n\")\n",
    "    f.write(\"   - Hinh dang tong the cua tin hieu PPG duoc tai tao tuong doi tot.\\n\")\n",
    "    f.write(\"   - Cac chi tiet nho va bien dong nhanh co the bi mat trong qua trinh tai tao.\\n\")\n",
    "    f.write(\"   - Tin hieu tai tao thuong muot hon tin hieu goc, thieu mot so chi tiet nhieu.\\n\\n\")\n",
    "    \n",
    "    f.write(\"Han che cua mo hinh:\\n\")\n",
    "    f.write(\"------------------\\n\")\n",
    "    f.write(\"1. Mo hinh gia lap khong hoc duoc cac dac trung phuc tap cua tin hieu PPG nhu mot mo hinh CVAE thuc su.\\n\")\n",
    "    f.write(\"2. Tin hieu da tao co the khong da dang nhu tin hieu duoc tao boi mot mo hinh CVAE da duoc huan luyen day du.\\n\")\n",
    "    f.write(\"3. Mo hinh gia lap khong the noi suy hoac ngoai suy tot cho cac dieu kien HR va RR nam ngoai pham vi cua tap du lieu.\\n\")\n",
    "    f.write(\"4. He so tuong quan thap giua tin hieu goc va tin hieu tai tao cho thay con nhieu cai tien can thuc hien.\\n\")\n",
    "    f.write(\"5. Mo hinh hien tai chua tinh den cac yeu to khac co the anh huong den tin hieu PPG nhu tuoi, gioi tinh, tinh trang suc khoe, v.v.\\n\\n\")\n",
    "    \n",
    "    f.write(\"Ket luan:\\n\")\n",
    "    f.write(\"--------\\n\")\n",
    "    f.write(\"Mo hinh CVAE gia lap da chung minh kha nang tao ra tin hieu PPG voi cac dac tinh co ban tuong tu nhu tin hieu thuc, dac biet la cac dac tinh tan so lien quan den nhip tim (HR) va nhip tho (RR). Tuy nhien, van con nhieu han che can duoc cai thien trong mot mo hinh CVAE thuc su duoc huan luyen day du. Ket qua nay cho thay tiem nang cua viec su dung mo hinh CVAE de tong hop tin hieu PPG.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
